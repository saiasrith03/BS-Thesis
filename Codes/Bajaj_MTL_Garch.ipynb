{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQuxpamGnGOU",
        "outputId": "7f07163d-8a5e-454d-ffba-c4c6a6ec61b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arch\n",
            "  Downloading arch-6.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (982 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/983.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.0/983.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.10/dist-packages (from arch) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from arch) (1.11.4)\n",
            "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.10/dist-packages (from arch) (1.5.3)\n",
            "Requirement already satisfied: statsmodels>=0.12 in /usr/local/lib/python3.10/dist-packages (from arch) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->arch) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1->arch) (2023.4)\n",
            "Requirement already satisfied: patsy>=0.5.4 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (0.5.6)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.12->arch) (24.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.4->statsmodels>=0.12->arch) (1.16.0)\n",
            "Installing collected packages: arch\n",
            "Successfully installed arch-6.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install arch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from datetime import timedelta\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "plt.style.use('fivethirtyeight') # For plots"
      ],
      "metadata": {
        "id": "umahFs1Unyjp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bajaj_df = pd.read_csv('bajaj.csv')\n",
        "bajaj_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "xBCyOnNvn164",
        "outputId": "0a16bb28-8249-4668-d83d-174ef76afccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'bajaj.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-d41d7a527287>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbajaj_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bajaj.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mbajaj_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bajaj.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bajaj_df = bajaj_df.drop_duplicates('Date', keep='last')\n",
        "bajaj_df"
      ],
      "metadata": {
        "id": "EbToYSCboAuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bajaj_df = bajaj_df.set_index('Date')\n",
        "bajaj_df.index = pd.to_datetime(bajaj_df.index)"
      ],
      "metadata": {
        "id": "EmWHgFxdoC2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bajaj_df.sort_index(inplace=True)"
      ],
      "metadata": {
        "id": "xC-i0TaEoEyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bajaj_df['Price'] = (bajaj_df['Price'].str.split()).apply(lambda x: float(x[0].replace(',', '')))\n",
        "bajaj_df['Open'] = (bajaj_df['Open'].str.split()).apply(lambda x: float(x[0].replace(',', '')))\n",
        "bajaj_df['High'] = (bajaj_df['High'].str.split()).apply(lambda x: float(x[0].replace(',', '')))\n",
        "bajaj_df['Low'] = (bajaj_df['Low'].str.split()).apply(lambda x: float(x[0].replace(',', '')))\n",
        "bajaj_df['Change %'] = (bajaj_df['Change %'].str.split()).apply(lambda x: float(x[0].replace('%', '')))\n",
        "bajaj_df.info()"
      ],
      "metadata": {
        "id": "JjdwRMUvoGKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = bajaj_df[['Price', 'Open', 'High', 'Low']].copy()\n",
        "df"
      ],
      "metadata": {
        "id": "YNdc-wSdoPj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()\n",
        "df"
      ],
      "metadata": {
        "id": "JFHhwpicoReB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ta"
      ],
      "metadata": {
        "id": "IVFQUeSEoYsD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# python -m pip install yahoo-finance; pip install yahoo-finance; pip install yfinance --upgrade --no-cache-dir\n",
        "# import yfinance as yf\n",
        "# pip install --upgrade ta; pip install ta\n",
        "import ta as ta\n",
        "import sklearn as sk\n",
        "from sklearn import preprocessing\n",
        "from scipy.stats import t\n",
        "import tensorflow as tf\n",
        "from datetime import date, datetime, timedelta\n",
        "from arch import arch_model\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "XfaisN7FobOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# python -m pip install yahoo-finance; pip install yahoo-finance; pip install yfinance --upgrade --no-cache-dir\n",
        "import yfinance as yf\n",
        "# !pip install --upgrade ta; pip install ta\n",
        "import ta as ta\n",
        "import sklearn as sk\n",
        "from sklearn import preprocessing\n",
        "from scipy.stats import t\n",
        "import tensorflow as tf\n",
        "from datetime import date, datetime, timedelta\n",
        "from arch import arch_model\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import math"
      ],
      "metadata": {
        "id": "k6fu37DFohv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Return calculation\n",
        "def ReturnCalculation (Database,lag):\n",
        "    dimension=Database.shape[0];dif=lag;Out=np.zeros([dimension-dif])\n",
        "    for i in range(dimension-dif):\n",
        "        Out[i]=(np.log(Database['Price'][i+dif])-np.log(Database['Price'][i]))\n",
        "    return np.append(np.repeat(np.nan, dif),Out), Database.index\n",
        "\n",
        "#STD Calculation\n",
        "def SDCalculation (DailyReturns, LagSD):\n",
        "    dimension=DailyReturns.shape[0]; dif=LagSD; Out=np.zeros([dimension-dif])\n",
        "    for i in range (dimension-dif):\n",
        "        Out[i]=np.std(DailyReturns[i:i+LagSD],ddof=1)\n",
        "    return np.append(np.repeat(np.nan, dif),Out)\n",
        "\n",
        "#STD Calculation\n",
        "def TrueSDCalculation (DailyReturns, LagSD):\n",
        "    dimension=DailyReturns.shape[0]; dif=LagSD; Out=np.zeros([dimension-dif+1])\n",
        "    for i in range (dimension-dif+1):\n",
        "        Out[i]=np.std(DailyReturns[i:i+LagSD],ddof=1)\n",
        "    return np.append(Out,np.repeat(np.nan, dif-1))\n",
        "\n",
        "#Database is calculated\n",
        "def DatabaseGeneration (Database, Lag, LagSD):\n",
        "    DailyReturns, Index = ReturnCalculation(Database,Lag)\n",
        "    DailyReturnsOld =  np.append(np.repeat(np.nan, 1),DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
        "    SD = SDCalculation (DailyReturns, LagSD)\n",
        "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
        "    Data = pd.DataFrame({'DailyReturns': DailyReturns, 'SD': SD, 'TrueSD': TrueSD, 'DailyReturnsOld': DailyReturnsOld})\n",
        "    Data = Data.set_index(Index)\n",
        "    return Data.dropna()\n",
        "\n",
        "#Fitting of GARCH(1,1)\n",
        "def GARCH_Model_Student (Data):\n",
        "    AR_Data=Data['DailyReturns']*100\n",
        "    GARCH11 = arch_model(AR_Data, dist ='t')\n",
        "    res_GARCH11 = GARCH11.fit(disp='off')\n",
        "    CV_GARCH11 = res_GARCH11.conditional_volatility\n",
        "    For_CV_GARCH11 = np.array(res_GARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
        "    return GARCH11, res_GARCH11, CV_GARCH11, For_CV_GARCH11\n",
        "\n",
        "#Fitting of GJR_GARCH(1,1)\n",
        "def GJR_GARCH_Model_Student (Data):\n",
        "    AR_Data=Data['DailyReturns']*100\n",
        "    GJR_GARCH11 = arch_model(AR_Data, p=1, o=1, q=1, dist ='t')\n",
        "    res_GJR_GARCH11 = GJR_GARCH11.fit(disp='off')\n",
        "    CV_GJR_GARCH11 = res_GJR_GARCH11.conditional_volatility\n",
        "    For_CV_GJR_GARCH11 = np.array(res_GJR_GARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
        "    return GJR_GARCH11, res_GJR_GARCH11, CV_GJR_GARCH11, For_CV_GJR_GARCH11\n",
        "\n",
        "#Fitting of TARCH(1,1)\n",
        "def TARCH_Model_Student(Data):\n",
        "    AR_Data=Data['DailyReturns']*100\n",
        "    TARCH11 = arch_model(AR_Data, p=1, o=1, q=1, power=1.0, dist ='t')\n",
        "    res_TARCH11 = TARCH11.fit(disp='off')\n",
        "    CV_TARCH11 = res_TARCH11.conditional_volatility\n",
        "    For_CV_TARCH11 = np.array(res_TARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
        "    return TARCH11, res_TARCH11, CV_TARCH11, For_CV_TARCH11\n",
        "\n",
        "#Fitting of EGARCH(1,1)\n",
        "def EGARCH_Model_Student(Data):\n",
        "    AR_Data=Data['DailyReturns']*100\n",
        "    EGARCH11 = arch_model(AR_Data, dist ='t', vol=\"EGARCH\")\n",
        "    res_EGARCH11 = EGARCH11.fit(disp='off')\n",
        "    CV_EGARCH11 = res_EGARCH11.conditional_volatility\n",
        "    For_CV_EGARCH11 = np.array(res_EGARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
        "    return EGARCH11, res_EGARCH11,CV_EGARCH11, For_CV_EGARCH11\n",
        "\n",
        "#Fitting of Absolute Value GARCH(1,1)\n",
        "def AVGARCH_Model_Student(Data):\n",
        "    AR_Data=Data['DailyReturns']*100\n",
        "    AVGARCH11 = arch_model(AR_Data, dist ='t', power=1)\n",
        "    res_AVGARCH11 = AVGARCH11.fit(disp='off',options={'maxiter': 1000})\n",
        "    CV_AVGARCH11 = res_AVGARCH11.conditional_volatility\n",
        "    For_CV_AVGARCH11 = np.array(res_AVGARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
        "    return AVGARCH11, res_AVGARCH11, CV_AVGARCH11, For_CV_AVGARCH11\n",
        "\n",
        "#Fitting of FIGARCH11(1,1)\n",
        "def FIGARCH_Model_Student(Data):\n",
        "    AR_Data=Data['DailyReturns']*100\n",
        "    FIGARCH11 = arch_model(AR_Data, dist ='t', vol=\"FIGARCH\")\n",
        "    res_FIGARCH11 = FIGARCH11.fit(disp='off')\n",
        "    CV_FIGARCH11 = res_FIGARCH11.conditional_volatility\n",
        "    For_CV_FIGARCH11 = np.array(res_FIGARCH11.forecast(horizon=1).variance.dropna())[0][0]\n",
        "    return FIGARCH11, res_FIGARCH11, CV_FIGARCH11, For_CV_FIGARCH11\n",
        "\n",
        "#AR models are fitted. As requested by arma package, returns are multiplied by 100 in order to improve the fitting process.\n",
        "#GARCH(1,1), GJR_GARCH(1,1), TARCH(1,1), EGARCH(1,1), AVGARCH(1,1) and FIGARCH(1,1) volatility models are fitted.\n",
        "#T student is assumed as distribution.\n",
        "def AR_Models (Data):\n",
        "    GARCH, GARCH_Parameters, CV_GARCH, For_CV_GARCH = GARCH_Model_Student(Data)\n",
        "    GJR_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH = GJR_GARCH_Model_Student(Data)\n",
        "    TARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH = TARCH_Model_Student(Data)\n",
        "    EGARCH, EGARCH_Parameters,CV_EGARCH, For_CV_EGARCH = EGARCH_Model_Student(Data)\n",
        "    AVGARCH, AVGARCH_Parameters,CV_AVGARCH, For_CV_AVGARCH = AVGARCH_Model_Student(Data)\n",
        "    FIGARCH, FIGARCH_Parameters,CV_FIGARCH, For_CV_FIGARCH  = FIGARCH_Model_Student(Data)\n",
        "    return GARCH_Parameters, CV_GARCH, For_CV_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH, EGARCH_Parameters,CV_EGARCH, For_CV_EGARCH, AVGARCH_Parameters,CV_AVGARCH, For_CV_AVGARCH, FIGARCH_Parameters,CV_FIGARCH, For_CV_FIGARCH\n",
        "\n",
        "#MultiHeadSelfAttention\n",
        "class MultiHeadSelfAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads=8):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        if embed_dim % num_heads != 0:\n",
        "            raise ValueError(f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\")\n",
        "        self.projection_dim = embed_dim // num_heads\n",
        "        self.query_dense = tf.keras.layers.Dense(embed_dim)\n",
        "        self.key_dense = tf.keras.layers.Dense(embed_dim)\n",
        "        self.value_dense = tf.keras.layers.Dense(embed_dim)\n",
        "        self.combine_heads = tf.keras.layers.Dense(embed_dim)\n",
        "    def attention(self, query, key, value):\n",
        "        score = tf.matmul(query, key, transpose_b=True)\n",
        "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "        scaled_score = score / tf.math.sqrt(dim_key)\n",
        "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
        "        output = tf.matmul(weights, value)\n",
        "        return output, weights\n",
        "    def separate_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    def call(self, inputs):\n",
        "        # x.shape = [batch_size, seq_len, embedding_dim]\n",
        "        batch_size = tf.shape(inputs)[0]\n",
        "        query = self.query_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        key = self.key_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        value = self.value_dense(inputs)  # (batch_size, seq_len, embed_dim)\n",
        "        query = self.separate_heads(query, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        key = self.separate_heads(key, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        value = self.separate_heads(value, batch_size)  # (batch_size, num_heads, seq_len, projection_dim)\n",
        "        attention, weights = self.attention(query, key, value)\n",
        "        attention = tf.transpose(attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len, num_heads, projection_dim)\n",
        "        concat_attention = tf.reshape(attention, (batch_size, -1, self.embed_dim))  # (batch_size, seq_len, embed_dim)\n",
        "        output = self.combine_heads(concat_attention)  # (batch_size, seq_len, embed_dim)\n",
        "        return output\n",
        "\n",
        "#Transformer Keras Block\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        # self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.nb_dict = {}; self.Bagging=5\n",
        "        for i in range(self.Bagging):\n",
        "          self.nb_dict[\"att{0}\".format(i)]=MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.ffn = tf.keras.Sequential([tf.keras.layers.Dense(ff_dim, activation=\"relu\"), tf.keras.layers.Dense(embed_dim),])\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    def call(self, inputs, training):\n",
        "        self.att_dict = {}\n",
        "        for i in range(self.Bagging):\n",
        "          self.att_dict[\"att{0}\".format(i)]=self.nb_dict[\"att{0}\".format(i)](tf.keras.layers.Dropout(.1)(inputs))\n",
        "          if i==0:\n",
        "            self.att_dict[\"attn_output\"]=self.att_dict[\"att{0}\".format(i)]/self.Bagging\n",
        "          else:\n",
        "            self.att_dict[\"attn_output\"]=self.att_dict[\"attn_output\"]+self.att_dict[\"att{0}\".format(i)]/self.Bagging\n",
        "        attn_output = self.dropout1(self.att_dict[\"attn_output\"], training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "def Transformer_Model (Shape1, Shape2, HeadsAttention,Dropout, LearningRate):\n",
        "    #Model struture is defined\n",
        "    Input = tf.keras.Input(shape=(Shape1,Shape2), name=\"Input\")\n",
        "    #LSTM is applied on top of the transformer\n",
        "    X = tf.keras.layers.LSTM(units=16, dropout=Dropout, return_sequences=True)(Input)\n",
        "    #Tranformer architecture is implemented\n",
        "    transformer_block_1 = TransformerBlock(embed_dim=16, num_heads=HeadsAttention, ff_dim=8, rate=Dropout)\n",
        "    X = transformer_block_1(X)\n",
        "    #Dense layers are used\n",
        "    X = tf.keras.layers.GlobalAveragePooling1D()(X)\n",
        "    X = tf.keras.layers.Dense(8, activation=tf.nn.sigmoid)(X)\n",
        "    X = tf.keras.layers.Dropout(Dropout)(X)\n",
        "    Output = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, name=\"Output\")(X)\n",
        "    model = tf.keras.Model(inputs=Input, outputs=Output)\n",
        "    #Optimizer is defined\n",
        "    Opt = tf.keras.optimizers.Adam(learning_rate=LearningRate, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,name='Adam')\n",
        "    #Model is compiled\n",
        "    model.compile(optimizer=Opt, loss='mean_squared_error', metrics=['mean_squared_error'])\n",
        "    return model\n",
        "\n",
        "#It generates the database for fitting transformer. No positional encoding is needed as LSTM plays this role in the model structure\n",
        "def Transformer_Database (Timestep, XData_AR, YData_AR):\n",
        "    Features = XData_AR.shape[1]; Sample = XData_AR.shape[0]-Timestep+1\n",
        "    print('Transformer DB features')\n",
        "    print(Features)\n",
        "    XDataTrainScaledRNN=np.zeros([Sample, Timestep, Features]); YDataTrainRNN=np.zeros([Sample])\n",
        "    for i in range(Sample):\n",
        "        XDataTrainScaledRNN[i,:,:] = XData_AR[i:(Timestep+i)]\n",
        "        YDataTrainRNN[i] = YData_AR[Timestep+i-1]\n",
        "    return XDataTrainScaledRNN, YDataTrainRNN\n",
        "\n",
        "#Database is calculated\n",
        "def DatabaseGenerationForecast (Database, Lag, LagSD):\n",
        "    DailyReturns, Index = ReturnCalculation(Database,Lag)\n",
        "    DailyReturnsOld =  np.append(np.repeat(np.nan, 1),DailyReturns[0:(DailyReturns.shape[0]-1)])\n",
        "    SD = SDCalculation (DailyReturns, LagSD)\n",
        "    TrueSD = TrueSDCalculation(DailyReturns, LagSD)\n",
        "    Data = pd.DataFrame({'DailyReturns': DailyReturns, 'SD': SD, 'TrueSD': TrueSD, 'DailyReturnsOld': DailyReturnsOld})\n",
        "    Data = Data.set_index(Index)\n",
        "    return Data\n",
        "\n",
        "#Final AR database for forcasting is generated\n",
        "def DatabaseGenerationForecast_AR (Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH):\n",
        "    Data_Forecast=DatabaseGenerationForecast(Database, Lag, LagSD).iloc[(-LagSD+1)]\n",
        "    Index_Forecast=DatabaseGenerationForecast(Database, Lag, LagSD).index[(-LagSD+1)]\n",
        "    XDataForecast={'SD': Data_Forecast['SD'], 'DailyReturnsOld': Data_Forecast['DailyReturnsOld'],\n",
        "               'CV_GARCH' : For_CV_GARCH/100, 'CV_GJR_GARCH' : For_CV_GJR_GARCH/100, 'CV_TARCH' : For_CV_TARCH/100,\n",
        "               'CV_EGARCH' : For_CV_EGARCH/100, 'CV_AVGARCH' : For_CV_AVGARCH/100, 'CV_FIGARCH' : For_CV_FIGARCH/100}\n",
        "    return pd.DataFrame([XDataForecast], index=[Index_Forecast]), Data_Forecast['DailyReturns']\n",
        "\n",
        "#Transformed ANN-ARCH model forecast\n",
        "def T_ANN_ARCH_Forecast (Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH,Scaled_Norm, XData_AR, model):\n",
        "    XDataForecast, ReturnForecast = DatabaseGenerationForecast_AR (Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH)\n",
        "    XDataForecast = pd.concat([XData_AR,XDataForecast])\n",
        "    XDataForecastTotalScaled = Scaled_Norm.transform(XDataForecast)\n",
        "    XDataForecastTotalScaled_T, Y_T = Transformer_Database(Timestep, XDataForecastTotalScaled, np.zeros(XDataForecastTotalScaled.shape[0]))\n",
        "    TransformerPrediction = model.predict(XDataForecastTotalScaled_T)\n",
        "    return TransformerPrediction[-1][0], XDataForecast.index[-1], TransformerPrediction[0:(XDataForecastTotalScaled_T.shape[0]-1)], ReturnForecast\n",
        "\n",
        "#It calculates VaR taking into consideration the forecasted sigma to calculate the scale parameter\n",
        "def T_ANN_ARCH_VaR (Alpha, HistoricalReturns, ForecastedSigma, DF):\n",
        "    HistoricalMean = np.mean(HistoricalReturns)\n",
        "    ScaleParameter = np.sqrt((ForecastedSigma**2)*((DF-2)/DF))\n",
        "    VaR = -t.ppf(Alpha, DF, loc=HistoricalMean, scale=ScaleParameter)\n",
        "    return VaR\n",
        "\n",
        "#Formula to calculate the VaR of ARCH models\n",
        "def VaR_AR_Model (AR_Model,AR_Model_Results,Alpha):\n",
        "    Cond_Var=AR_Model_Results.forecast(horizon=1).variance.dropna()\n",
        "    Cond_Mean=AR_Model_Results.forecast(horizon=1).mean.dropna()\n",
        "    Quantile_Dist=AR_Model.distribution.ppf([Alpha], AR_Model_Results.params[-1:])\n",
        "    VaR=(-Cond_Mean-np.sqrt(Cond_Var)*Quantile_Dist)/100\n",
        "    return VaR.values\n",
        "\n",
        "#Formula to calculate the VaR of all the ARCH models\n",
        "def VaR_AR_Total(Alpha, GARCH_fit, GJR_GARCH_fit, TARCH_fit, EGARCH_fit, AVGARCH_fit, FIGARCH_fit,GARCH, GJR_GARCH, TARCH, EGARCH, AVGARCH, FIGARCH):\n",
        "    VaR_GARCH = VaR_AR_Model (GARCH,GARCH_fit,Alpha)\n",
        "    VaR_GJR_GARCH = VaR_AR_Model (GJR_GARCH,GJR_GARCH_fit,Alpha)\n",
        "    VaR_TARCH = VaR_AR_Model (TARCH,TARCH_fit,Alpha)\n",
        "    VaR_EGARCH = VaR_AR_Model (EGARCH,EGARCH_fit,Alpha)\n",
        "    VaR_AVGARCH = VaR_AR_Model (AVGARCH,AVGARCH_fit,Alpha)\n",
        "    VaR_FIGARCH = VaR_AR_Model (FIGARCH,FIGARCH_fit,Alpha)\n",
        "    return {'VaR_GARCH':VaR_GARCH, 'VaR_GJR_GARCH':VaR_GJR_GARCH, 'VaR_TARCH':VaR_TARCH, 'VaR_EGARCH':VaR_EGARCH, 'VaR_AVGARCH':VaR_AVGARCH, 'VaR_FIGARCH':VaR_FIGARCH}\n",
        "\n",
        "# #Traditional emmbeding position for NLP in transformers\n",
        "# def position_encoding_init(n_position, d_pos_vec):\n",
        "#     # keep dim 0 for padding token position encoding zero vector\n",
        "#     position_enc = np.array([\n",
        "#         [pos / np.power(10000, 2*i/d_pos_vec) for i in range(d_pos_vec)]\n",
        "#         if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "#     position_enc[1:, 0::2] = np.sin(position_enc[1:, 0::2]) # dim 2i\n",
        "#     position_enc[1:, 1::2] = np.cos(position_enc[1:, 1::2]) # dim 2i+1\n",
        "#     return position_enc\n",
        "# #Encoding only for the temporal component of the variables.For non-NLP problems.\n",
        "# def position_encoding_init(n_position, d_pos_vec):\n",
        "#     position_enc = np.array([\n",
        "#         [math.pi*(pos/(n_position-1)) for i in range(d_pos_vec)]\n",
        "#         if pos != 0 else np.zeros(d_pos_vec) for pos in range(n_position)])\n",
        "#     return np.cos(position_enc)\n",
        "\n",
        "#Fitting of Transformed ANN-ARCH model and forecasting of the next volatility value\n",
        "def T_ANN_ARCH_Fit (Data, Lag=1, LagSD=5, Timestep=10, Dropout=0.05, LearningRate=0.01, Epochs=10000, Alpha=0.005, DF=4, BatchSize=64):\n",
        "    #AR Models are fitted\n",
        "    GARCH, GARCH_Parameters, CV_GARCH, For_CV_GARCH = GARCH_Model_Student(Data)\n",
        "    GJR_GARCH, GJR_GARCH_Parameters, CV_GJR_GARCH, For_CV_GJR_GARCH = GJR_GARCH_Model_Student(Data)\n",
        "    TARCH, TARCH_Parameters, CV_TARCH, For_CV_TARCH = TARCH_Model_Student(Data)\n",
        "    EGARCH, EGARCH_Parameters,CV_EGARCH, For_CV_EGARCH = EGARCH_Model_Student(Data)\n",
        "    AVGARCH, AVGARCH_Parameters,CV_AVGARCH, For_CV_AVGARCH = AVGARCH_Model_Student(Data)\n",
        "    FIGARCH, FIGARCH_Parameters,CV_FIGARCH, For_CV_FIGARCH  = FIGARCH_Model_Student(Data)\n",
        "    #Database contaning AR models is generated\n",
        "    Data_AR=pd.concat([Data, CV_GARCH.rename('CV_GARCH')/100, CV_GJR_GARCH.rename('CV_GJR_GARCH')/100, CV_TARCH.rename('CV_TARCH')/100,\n",
        "                     CV_EGARCH.rename('CV_EGARCH')/100, CV_AVGARCH.rename('CV_AVGARCH')/100, CV_FIGARCH.rename('CV_FIGARCH')/100], axis=1)\n",
        "\n",
        "    if Data_AR.shape[0]!=Data.shape[0]: print(\"Error in DB Generation\")\n",
        "    #Original explanatory and response variables are generated\n",
        "    XData_AR = Data_AR.drop(Data_AR.columns[[0,2]], axis=1);YData_AR = Data_AR['TrueSD']\n",
        "    #Data is normalized\n",
        "    Scaled_Norm = preprocessing.StandardScaler().fit(XData_AR); XData_AR_Norm = Scaled_Norm.transform(XData_AR)\n",
        "    #Data for fitting the transformer model is generated\n",
        "    XData_AR_Norm_T, YData_AR_Norm_T= Transformer_Database(Timestep, XData_AR_Norm, YData_AR)\n",
        "    #Model with transformer layer is defined\n",
        "    model = Transformer_Model(XData_AR_Norm_T.shape[1], XData_AR_Norm_T.shape[2], HeadsAttention=4, Dropout=Dropout, LearningRate=LearningRate)\n",
        "    model.fit(XData_AR_Norm_T, YData_AR_Norm_T, epochs=Epochs, verbose=0, batch_size=BatchSize); tf.keras.backend.clear_session()\n",
        "    Forecast, Date_Forecast, TrainPrediction, ReturnForecast = T_ANN_ARCH_Forecast (Database, Lag, LagSD, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH,Scaled_Norm, XData_AR, model)\n",
        "    VaR = T_ANN_ARCH_VaR(Alpha, Data['DailyReturnsOld'], Forecast,DF)\n",
        "    return {'T_ANN_ARCH_model':model, 'Forecast_T_ANN_ARCH':Forecast, 'Date_Forecast':Date_Forecast, 'TrainPrediction': TrainPrediction, 'Scaler':Scaled_Norm, 'Forecast_GARCH':For_CV_GARCH, 'Forecast_GJR_GARCH':For_CV_GJR_GARCH, 'Forecast_TARCH':For_CV_TARCH, 'Forecast_EGARCH':For_CV_EGARCH, 'Forecast_AVGARCH':For_CV_AVGARCH, 'Forecast_FIGARCH':For_CV_FIGARCH, 'ReturnForecast':ReturnForecast, 'GARCH_fit': GARCH_Parameters, 'GJR_GARCH_fit':GJR_GARCH_Parameters, 'TARCH_fit':TARCH_Parameters, 'EGARCH_fit':EGARCH_Parameters, 'AVGARCH_fit':AVGARCH_Parameters, 'FIGARCH_fit':FIGARCH_Parameters, 'GARCH': GARCH, 'GJR_GARCH':GJR_GARCH, 'TARCH':TARCH, 'EGARCH':EGARCH, 'AVGARCH':AVGARCH, 'FIGARCH':FIGARCH, 'YData_Train':YData_AR_Norm_T, 'VaR': VaR}\n",
        "#     return (model, Forecast, Date_Forecast, TrainPrediction, Scaled_Norm, For_CV_GARCH, For_CV_GJR_GARCH, For_CV_TARCH, For_CV_EGARCH, For_CV_AVGARCH, For_CV_FIGARCH, ReturnForecast, GARCH_Parameters, GJR_GARCH_Parameters, TARCH_Parameters, EGARCH_Parameters, AVGARCH_Parameters, FIGARCH_Parameters, GARCH, GJR_GARCH, TARCH, EGARCH, AVGARCH, FIGARCH, YData_AR_Norm_T)"
      ],
      "metadata": {
        "id": "5oZwabYEopDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = df.loc[:'2022-12-30'].reset_index(drop=False)\n",
        "test_df = df.loc['2023-01-02':].reset_index(drop=False)"
      ],
      "metadata": {
        "id": "nwV1_gXpotqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_df.set_index('Date')\n",
        "test_df = test_df.set_index('Date')"
      ],
      "metadata": {
        "id": "9naO-kw7o6I-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trIndexEndDays = train_df.index\n",
        "trIndexDates = trIndexEndDays[2000:]"
      ],
      "metadata": {
        "id": "8T1bx4R_o7d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Lag=1; LagSD=5; Timestep=10; Dropout=0.15; LearningRate=0.01; Epochs=50; Alpha=0.005; DF=4\n",
        "DataValidation = DatabaseGeneration(df, Lag, LagSD)\n",
        "ResultsCollection=pd.DataFrame({'Date_Forecast': [], 'Forecast_T_ANN_ARCH': [],'Forecast_GARCH':[],'Forecast_GJR_GARCH':[], 'Forecast_TARCH':[],'Forecast_EGARCH':[],'Forecast_AVGARCH':[],'Forecast_FIGARCH':[],'ReturnForecast':[],'TrueSD':[], 'VaR_T_ANN_ARCH':[], 'VaR_GARCH':[], 'VaR_GJR_GARCH':[], 'VaR_TARCH':[], 'VaR_EGARCH':[], 'VaR_AVGARCH':[], 'VaR_FIGARCH':[]})\n"
      ],
      "metadata": {
        "id": "IORSomUSo8x7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in tqdm(range(trIndexDates.shape[0])):\n",
        "    #Database is downloaded from yahoo finance and lag of returns defined\n",
        "    Database=df.loc[(pd.to_datetime(df.index).date >= trIndexDates[i].date()-timedelta(days=650)) & (pd.to_datetime(df.index).date <= trIndexDates[i].date())]\n",
        "    #Database for fitting the models is generated\n",
        "    Data = DatabaseGeneration (Database, Lag, LagSD)\n",
        "\n",
        "    #Fitting of Transformed ANN-ARCH model, ARCH models and forecasting of the next volatility value\n",
        "    T_ANN_ARCH_Model = T_ANN_ARCH_Fit (Data, Lag, LagSD, Timestep, Dropout, LearningRate, Epochs, Alpha, DF)\n",
        "    #VaR of ARCH models is computed\n",
        "    VaR_ARCH_Models=VaR_AR_Total(Alpha, T_ANN_ARCH_Model['GARCH_fit'], T_ANN_ARCH_Model['GJR_GARCH_fit'], T_ANN_ARCH_Model['TARCH_fit'], T_ANN_ARCH_Model['EGARCH_fit'], T_ANN_ARCH_Model['AVGARCH_fit'], T_ANN_ARCH_Model['FIGARCH_fit'],T_ANN_ARCH_Model['GARCH'], T_ANN_ARCH_Model['GJR_GARCH'], T_ANN_ARCH_Model['TARCH'], T_ANN_ARCH_Model['EGARCH'], T_ANN_ARCH_Model['AVGARCH'], T_ANN_ARCH_Model['FIGARCH'])\n",
        "    #Results are collected\n",
        "    IterResults={'Date_Forecast': T_ANN_ARCH_Model['Date_Forecast'].date(), 'Forecast_T_ANN_ARCH': T_ANN_ARCH_Model['Forecast_T_ANN_ARCH'],'Forecast_GARCH':T_ANN_ARCH_Model['Forecast_GARCH']/100,'Forecast_GJR_GARCH':T_ANN_ARCH_Model['Forecast_GJR_GARCH']/100, 'Forecast_TARCH':T_ANN_ARCH_Model['Forecast_TARCH']/100,'Forecast_EGARCH':T_ANN_ARCH_Model['Forecast_EGARCH']/100,'Forecast_AVGARCH':T_ANN_ARCH_Model['Forecast_AVGARCH']/100,'Forecast_FIGARCH':T_ANN_ARCH_Model['Forecast_FIGARCH']/100,'ReturnForecast':T_ANN_ARCH_Model['ReturnForecast'],'TrueSD':DataValidation[DataValidation.index==pd.to_datetime(T_ANN_ARCH_Model['Date_Forecast'].date())]['TrueSD'][0], 'VaR_T_ANN_ARCH': T_ANN_ARCH_Model['VaR'], 'VaR_GARCH':VaR_ARCH_Models['VaR_GARCH'][0][0], 'VaR_GJR_GARCH':VaR_ARCH_Models['VaR_GJR_GARCH'][0][0], 'VaR_TARCH':VaR_ARCH_Models['VaR_TARCH'][0][0], 'VaR_EGARCH':VaR_ARCH_Models['VaR_EGARCH'][0][0], 'VaR_AVGARCH':VaR_ARCH_Models['VaR_AVGARCH'][0][0], 'VaR_FIGARCH':VaR_ARCH_Models['VaR_FIGARCH'][0][0]}\n",
        "    ResultsCollection=ResultsCollection.append(IterResults, ignore_index=True)\n",
        "    #Results are saved\n",
        "    ResultsCollection.to_csv('5_MTL_GARCH.csv',index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T8tsxdjPpCrv",
        "outputId": "86c35120-1409-4170-acbd-a79eb0a8ff34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/744 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Price    Open    High     Low\n",
            "Date                                      \n",
            "2018-03-28  517.15  523.00  529.90  502.15\n",
            "2018-04-02  526.74  507.50  529.50  507.12\n",
            "2018-04-03  538.16  526.90  541.85  523.26\n",
            "2018-04-04  522.86  542.00  544.56  520.28\n",
            "2018-04-05  544.38  533.30  550.00  531.50\n",
            "...            ...     ...     ...     ...\n",
            "2020-01-01  937.85  942.00  943.25  935.20\n",
            "2020-01-02  950.56  937.85  953.10  937.85\n",
            "2020-01-03  934.59  946.50  950.46  932.40\n",
            "2020-01-06  904.27  933.90  933.90  902.20\n",
            "2020-01-07  909.57  912.50  926.50  906.50\n",
            "\n",
            "[437 rows x 4 columns]\n",
            "////\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld\n",
            "Date                                                         \n",
            "2018-04-09      0.013961  0.025601  0.016668         0.007394\n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961\n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047\n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348\n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111\n",
            "...                  ...       ...       ...              ...\n",
            "2019-12-26      0.005921  0.004885  0.005991        -0.000979\n",
            "2019-12-27      0.009908  0.005925  0.007927         0.005921\n",
            "2019-12-30     -0.000424  0.004299  0.010876         0.009908\n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424\n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864\n",
            "\n",
            "[427 rows x 4 columns]\n",
            "GARCH\n",
            "Date\n",
            "2018-04-09    1.677962\n",
            "2018-04-10    1.650561\n",
            "2018-04-11    2.018000\n",
            "2018-04-12    1.805067\n",
            "2018-04-13    1.644586\n",
            "                ...   \n",
            "2019-12-26    1.285152\n",
            "2019-12-27    1.280552\n",
            "2019-12-30    1.318948\n",
            "2019-12-31    1.291410\n",
            "2020-01-01    1.302919\n",
            "Name: cond_vol, Length: 427, dtype: float64\n",
            "---------\n",
            "GJR GARCH\n",
            "Date\n",
            "2018-04-09    1.667055\n",
            "2018-04-10    1.590863\n",
            "2018-04-11    2.152364\n",
            "2018-04-12    1.933321\n",
            "2018-04-13    1.756233\n",
            "                ...   \n",
            "2019-12-26    1.226000\n",
            "2019-12-27    1.207879\n",
            "2019-12-30    1.215558\n",
            "2019-12-31    1.195147\n",
            "2020-01-01    1.224035\n",
            "Name: cond_vol, Length: 427, dtype: float64\n",
            "---------\n",
            "T_ANN_ARCH_FIT Data_AR\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld  CV_GARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-09      0.013961  0.025601  0.016668         0.007394  0.016780   \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961  0.016506   \n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047  0.020180   \n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348  0.018051   \n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111  0.016446   \n",
            "...                  ...       ...       ...              ...       ...   \n",
            "2019-12-26      0.005921  0.004885  0.005991        -0.000979  0.012852   \n",
            "2019-12-27      0.009908  0.005925  0.007927         0.005921  0.012806   \n",
            "2019-12-30     -0.000424  0.004299  0.010876         0.009908  0.013189   \n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424  0.012914   \n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864  0.013029   \n",
            "\n",
            "            CV_GJR_GARCH  CV_TARCH  CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                                                   \n",
            "2018-04-09      0.016671  0.013306   0.016719    0.014007    0.018264  \n",
            "2018-04-10      0.015909  0.012952   0.017036    0.015149    0.017433  \n",
            "2018-04-11      0.021524  0.018230   0.020805    0.019255    0.021725  \n",
            "2018-04-12      0.019333  0.016565   0.017669    0.016391    0.018108  \n",
            "2018-04-13      0.017562  0.015342   0.015596    0.014566    0.016572  \n",
            "...                  ...       ...        ...         ...         ...  \n",
            "2019-12-26      0.012260  0.011546   0.011371    0.011526    0.012162  \n",
            "2019-12-27      0.012079  0.011112   0.011438    0.011692    0.012088  \n",
            "2019-12-30      0.012156  0.010919   0.012319    0.012634    0.012560  \n",
            "2019-12-31      0.011951  0.010684   0.011653    0.011948    0.012032  \n",
            "2020-01-01      0.012240  0.011456   0.012015    0.012364    0.012226  \n",
            "\n",
            "[427 rows x 10 columns]\n",
            "==================\n",
            "XDATA_AR\n",
            "                  SD  DailyReturnsOld  CV_GARCH  CV_GJR_GARCH  CV_TARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-09  0.025601         0.007394  0.016780      0.016671  0.013306   \n",
            "2018-04-10  0.025391         0.013961  0.016506      0.015909  0.012952   \n",
            "2018-04-11  0.029296        -0.027047  0.020180      0.021524  0.018230   \n",
            "2018-04-12  0.024242         0.001348  0.018051      0.019333  0.016565   \n",
            "2018-04-13  0.015647         0.000111  0.016446      0.017562  0.015342   \n",
            "...              ...              ...       ...           ...       ...   \n",
            "2019-12-26  0.004885        -0.000979  0.012852      0.012260  0.011546   \n",
            "2019-12-27  0.005925         0.005921  0.012806      0.012079  0.011112   \n",
            "2019-12-30  0.004299         0.009908  0.013189      0.012156  0.010919   \n",
            "2019-12-31  0.004560        -0.000424  0.012914      0.011951  0.010684   \n",
            "2020-01-01  0.005910        -0.004864  0.013029      0.012240  0.011456   \n",
            "\n",
            "            CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                           \n",
            "2018-04-09   0.016719    0.014007    0.018264  \n",
            "2018-04-10   0.017036    0.015149    0.017433  \n",
            "2018-04-11   0.020805    0.019255    0.021725  \n",
            "2018-04-12   0.017669    0.016391    0.018108  \n",
            "2018-04-13   0.015596    0.014566    0.016572  \n",
            "...               ...         ...         ...  \n",
            "2019-12-26   0.011371    0.011526    0.012162  \n",
            "2019-12-27   0.011438    0.011692    0.012088  \n",
            "2019-12-30   0.012319    0.012634    0.012560  \n",
            "2019-12-31   0.011653    0.011948    0.012032  \n",
            "2020-01-01   0.012015    0.012364    0.012226  \n",
            "\n",
            "[427 rows x 8 columns]\n",
            "YDATA_AR\n",
            "Date\n",
            "2018-04-09    0.016668\n",
            "2018-04-10    0.016372\n",
            "2018-04-11    0.012233\n",
            "2018-04-12    0.013067\n",
            "2018-04-13    0.013197\n",
            "                ...   \n",
            "2019-12-26    0.005991\n",
            "2019-12-27    0.007927\n",
            "2019-12-30    0.010876\n",
            "2019-12-31    0.017420\n",
            "2020-01-01    0.018609\n",
            "Name: TrueSD, Length: 427, dtype: float64\n",
            "Transformer DB features\n",
            "8\n",
            "For loop transformer db\n",
            "%%%%%%%%%%%%%%%%%%%\n",
            "[[[ 0.8520561   0.31575546 -0.37402787 ... -0.40302061 -0.94437557\n",
            "   -0.23943665]\n",
            "  [ 0.83154758  0.65476718 -0.41832086 ... -0.34640327 -0.72736116\n",
            "   -0.35936475]\n",
            "  [ 1.21183669 -1.46225931  0.17564932 ...  0.32693117  0.05286888\n",
            "    0.25963529]\n",
            "  ...\n",
            "  [-0.44961652  0.31506536 -0.49159314 ... -0.4383698  -0.53014773\n",
            "   -0.56465164]\n",
            "  [-0.36837775 -0.58518191 -0.52059478 ... -0.41065088 -0.46848827\n",
            "   -0.56282149]\n",
            "  [-0.35576994  0.0626635  -0.69105945 ... -0.7420089  -0.83042236\n",
            "   -0.76575298]]\n",
            "\n",
            " [[ 0.83154758  0.65476718 -0.41832086 ... -0.34640327 -0.72736116\n",
            "   -0.35936475]\n",
            "  [ 1.21183669 -1.46225931  0.17564932 ...  0.32693117  0.05286888\n",
            "    0.25963529]\n",
            "  [ 0.7197114   0.00362068 -0.16856045 ... -0.23335585 -0.49125261\n",
            "   -0.26203132]\n",
            "  ...\n",
            "  [-0.36837775 -0.58518191 -0.52059478 ... -0.41065088 -0.46848827\n",
            "   -0.56282149]\n",
            "  [-0.35576994  0.0626635  -0.69105945 ... -0.7420089  -0.83042236\n",
            "   -0.76575298]\n",
            "  [-0.38338877 -1.0228757  -0.36731708 ... -0.29533752 -0.3548979\n",
            "   -0.36942867]]\n",
            "\n",
            " [[ 1.21183669 -1.46225931  0.17564932 ...  0.32693117  0.05286888\n",
            "    0.25963529]\n",
            "  [ 0.7197114   0.00362068 -0.16856045 ... -0.23335585 -0.49125261\n",
            "   -0.26203132]\n",
            "  [-0.117149   -0.06024136 -0.42798081 ... -0.60359889 -0.837996\n",
            "   -0.48351358]\n",
            "  ...\n",
            "  [-0.35576994  0.0626635  -0.69105945 ... -0.7420089  -0.83042236\n",
            "   -0.76575298]\n",
            "  [-0.38338877 -1.0228757  -0.36731708 ... -0.29533752 -0.3548979\n",
            "   -0.36942867]\n",
            "  [-0.6103579   0.0091866  -0.57882633 ... -0.68894447 -0.78845483\n",
            "   -0.69036599]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.02069213  0.16493209 -0.78881416 ... -0.79247897 -0.83427259\n",
            "   -0.87562893]\n",
            "  [-1.0209676   0.36829468 -0.82800189 ... -0.82869605 -0.86446924\n",
            "   -0.89920836]\n",
            "  [-1.19574693  0.3415166  -0.86380037 ... -0.87389396 -0.90668758\n",
            "   -0.94088996]\n",
            "  ...\n",
            "  [-1.16506057 -0.11647385 -1.00901125 ... -1.35816952 -1.4158123\n",
            "   -1.11947741]\n",
            "  [-1.06383692  0.23972648 -1.01644729 ... -1.34625665 -1.38419147\n",
            "   -1.1301253 ]\n",
            "  [-1.2220792   0.44554051 -0.95438006 ... -1.18893742 -1.20528157\n",
            "   -1.06202233]]\n",
            "\n",
            " [[-1.0209676   0.36829468 -0.82800189 ... -0.82869605 -0.86446924\n",
            "   -0.89920836]\n",
            "  [-1.19574693  0.3415166  -0.86380037 ... -0.87389396 -0.90668758\n",
            "   -0.94088996]\n",
            "  [-1.2589449  -0.06099298 -0.93741853 ... -1.08298113 -1.1391087\n",
            "   -1.02827888]\n",
            "  ...\n",
            "  [-1.06383692  0.23972648 -1.01644729 ... -1.34625665 -1.38419147\n",
            "   -1.1301253 ]\n",
            "  [-1.2220792   0.44554051 -0.95438006 ... -1.18893742 -1.20528157\n",
            "   -1.06202233]\n",
            "  [-1.19672474 -0.08782815 -0.99889482 ... -1.30791048 -1.33560959\n",
            "   -1.13809248]]\n",
            "\n",
            " [[-1.19574693  0.3415166  -0.86380037 ... -0.87389396 -0.90668758\n",
            "   -0.94088996]\n",
            "  [-1.2589449  -0.06099298 -0.93741853 ... -1.08298113 -1.1391087\n",
            "   -1.02827888]\n",
            "  [-0.90903915 -0.57463786 -0.82635102 ... -0.88596559 -0.9186953\n",
            "   -0.88772386]\n",
            "  ...\n",
            "  [-1.2220792   0.44554051 -0.95438006 ... -1.18893742 -1.20528157\n",
            "   -1.06202233]\n",
            "  [-1.19672474 -0.08782815 -0.99889482 ... -1.30791048 -1.33560959\n",
            "   -1.13809248]\n",
            "  [-1.06522202 -0.31705677 -0.98029068 ... -1.24317021 -1.25656288\n",
            "   -1.11024163]]]\n",
            "$$$$$$$$$$$$$$$$$$\n",
            "[0.01778587 0.01658115 0.01644887 0.01392534 0.01422053 0.01229865\n",
            " 0.00972776 0.00867076 0.00892153 0.01207872 0.01647356 0.01615604\n",
            " 0.01500122 0.0167847  0.02261649 0.02360776 0.02452643 0.02698428\n",
            " 0.03263853 0.02838046 0.0310246  0.0321993  0.02819379 0.02367704\n",
            " 0.02396434 0.018583   0.02006291 0.01950072 0.02265231 0.02314761\n",
            " 0.01812537 0.00956141 0.01002206 0.00695038 0.00540218 0.00649334\n",
            " 0.00518429 0.00660587 0.00821767 0.00931347 0.01582522 0.01621642\n",
            " 0.01604295 0.01925161 0.02107853 0.00849757 0.0070789  0.01565774\n",
            " 0.01916478 0.01401718 0.01344408 0.01034613 0.00969791 0.01075147\n",
            " 0.01443171 0.01375368 0.01641316 0.01690522 0.01363059 0.01239572\n",
            " 0.02820727 0.02706274 0.03128517 0.03061225 0.02674777 0.0226456\n",
            " 0.01510742 0.01384968 0.01167405 0.01101683 0.00934521 0.0092174\n",
            " 0.00894502 0.00960887 0.00546016 0.00565788 0.01206904 0.01564281\n",
            " 0.01575449 0.01574223 0.01591303 0.01185865 0.00558475 0.00573126\n",
            " 0.00536756 0.00604959 0.00303584 0.00305214 0.0104105  0.01003649\n",
            " 0.01094347 0.01082301 0.01409711 0.01320463 0.02046955 0.01959908\n",
            " 0.02038922 0.02992722 0.03242985 0.02525232 0.03088863 0.03048972\n",
            " 0.01356763 0.02177392 0.02274166 0.0239988  0.02498421 0.02297674\n",
            " 0.01852934 0.01526768 0.01803843 0.01777994 0.02168908 0.05283721\n",
            " 0.06135608 0.05740498 0.06124139 0.06127047 0.04188313 0.0349393\n",
            " 0.02497693 0.0242276  0.03591097 0.02793336 0.02784666 0.02193783\n",
            " 0.0194116  0.00432954 0.00404744 0.01198148 0.01195197 0.01093781\n",
            " 0.0106387  0.00853092 0.01595972 0.01561462 0.01549642 0.01519679\n",
            " 0.01633771 0.00644136 0.00870514 0.01349936 0.01984896 0.01847835\n",
            " 0.02126085 0.0218874  0.0230764  0.01840597 0.01858194 0.0166817\n",
            " 0.0220642  0.02173743 0.02940537 0.03066572 0.03305737 0.03401424\n",
            " 0.0246027  0.02354677 0.01871444 0.01790165 0.02144812 0.02031551\n",
            " 0.02137692 0.02111941 0.02296861 0.01525515 0.01669552 0.01628707\n",
            " 0.0131568  0.01382618 0.01368438 0.01115956 0.01118074 0.01091927\n",
            " 0.00487038 0.00532377 0.00470857 0.00471091 0.01142992 0.01144337\n",
            " 0.01413047 0.01600479 0.01969938 0.01666903 0.01707246 0.01630034\n",
            " 0.0152526  0.02144472 0.02751147 0.02673544 0.0278577  0.02815695\n",
            " 0.0207339  0.01227964 0.02133929 0.01665654 0.01826685 0.01816911\n",
            " 0.01820562 0.00960425 0.00909611 0.00899242 0.01187913 0.01523953\n",
            " 0.01519298 0.0192084  0.01891998 0.010463   0.0105996  0.01360099\n",
            " 0.01103831 0.01236519 0.0108059  0.00890935 0.00803958 0.00808686\n",
            " 0.01050686 0.01009772 0.01024592 0.00896467 0.00973217 0.00502041\n",
            " 0.0060571  0.00651612 0.00624908 0.00700831 0.00652003 0.00618053\n",
            " 0.00629767 0.0083634  0.00900904 0.01003294 0.00901974 0.01220903\n",
            " 0.01217357 0.01332609 0.01169683 0.00924914 0.00932588 0.00987151\n",
            " 0.00909439 0.0093536  0.00975013 0.00798102 0.00828214 0.01189389\n",
            " 0.01147718 0.01142665 0.01668842 0.01694362 0.01458934 0.01472795\n",
            " 0.01524071 0.0162221  0.01822313 0.01773328 0.01651045 0.01680327\n",
            " 0.01148143 0.01312327 0.02060673 0.01746681 0.02015685 0.02127158\n",
            " 0.02917684 0.02133082 0.01629192 0.01676039 0.01650755 0.01064498\n",
            " 0.00890362 0.01211514 0.01062052 0.01637348 0.01600519 0.0167101\n",
            " 0.01397077 0.01393007 0.00737196 0.00799769 0.00707274 0.01133755\n",
            " 0.01126958 0.01417131 0.01357984 0.01090321 0.00968406 0.00991858\n",
            " 0.00507851 0.00587077 0.00470996 0.00608701 0.00637849 0.00841441\n",
            " 0.00921439 0.04682072 0.05338705 0.05321183 0.05143143 0.0534651\n",
            " 0.02158339 0.01744301 0.01068289 0.01057116 0.02073705 0.03045701\n",
            " 0.0253212  0.02406746 0.02221231 0.04645246 0.03958041 0.03960738\n",
            " 0.0390337  0.03185376 0.0068513  0.00507705 0.00972455 0.0102742\n",
            " 0.01250509 0.014914   0.03425918 0.03915376 0.03923513 0.03919975\n",
            " 0.0368963  0.02558971 0.02179359 0.02575863 0.03723891 0.03654392\n",
            " 0.03655854 0.02400689 0.02433664 0.01385381 0.01370793 0.01260864\n",
            " 0.01605885 0.01619339 0.01260894 0.01450524 0.01329494 0.01464124\n",
            " 0.01314022 0.01550848 0.01557534 0.03577498 0.04334804 0.04073104\n",
            " 0.0421828  0.03761028 0.03263566 0.01289557 0.01278992 0.01308288\n",
            " 0.00987416 0.00612695 0.01090542 0.01173132 0.0115287  0.01029979\n",
            " 0.01001886 0.01013492 0.01382568 0.01411854 0.02056842 0.02080767\n",
            " 0.01992447 0.01551982 0.01647635 0.01202702 0.0127616  0.0130478\n",
            " 0.01482056 0.01848161 0.01846184 0.01841059 0.01835362 0.01787742\n",
            " 0.00949392 0.00766571 0.00463801 0.00555199 0.00419528 0.00380534\n",
            " 0.00671555 0.00563002 0.00567708 0.00885541 0.00907483 0.00935302\n",
            " 0.00888578 0.01207091 0.01193044 0.01503192 0.01340349 0.01304874\n",
            " 0.01282505 0.01196085 0.00809172 0.01185992 0.01132837 0.00636772\n",
            " 0.0063649  0.00456988 0.00392083 0.00751442 0.00741226 0.00645107\n",
            " 0.00488504 0.00592462 0.00429945 0.00455984 0.0059104  0.00599059\n",
            " 0.0079265  0.01087642 0.01741999 0.01860908]\n",
            "Transformer DB features\n",
            "8\n",
            "14/14 [==============================] - 2s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-07c24de7141f>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ResultsCollection=ResultsCollection.append(IterResults, ignore_index=True)\n",
            "\r  0%|          | 1/744 [00:14<3:05:43, 15.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results\n",
            "{'Date_Forecast': datetime.date(2020, 1, 2), 'Forecast_T_ANN_ARCH': 0.019780971, 'Forecast_GARCH': 0.016515723017294683, 'Forecast_GJR_GARCH': 0.014597789659189111, 'Forecast_TARCH': 0.012978070659284406, 'Forecast_EGARCH': 0.013549220981468924, 'Forecast_AVGARCH': 0.014379407202532288, 'Forecast_FIGARCH': 0.014162744925964246, 'ReturnForecast': 0.013461263101080867, 'TrueSD': 0.019321886719457306, 'VaR_T_ANN_ARCH': 0.06312107880495378, 'VaR_GARCH': 0.039498634523817945, 'VaR_GJR_GARCH': 0.036920470349978654, 'VaR_TARCH': 0.03484857419662712, 'VaR_EGARCH': 0.03571077212470955, 'VaR_AVGARCH': 0.036842080455310317, 'VaR_FIGARCH': 0.037037528569469014}\n",
            "             Price    Open    High     Low\n",
            "Date                                      \n",
            "2018-04-02  526.74  507.50  529.50  507.12\n",
            "2018-04-03  538.16  526.90  541.85  523.26\n",
            "2018-04-04  522.86  542.00  544.56  520.28\n",
            "2018-04-05  544.38  533.30  550.00  531.50\n",
            "2018-04-06  548.42  546.33  551.39  541.50\n",
            "...            ...     ...     ...     ...\n",
            "2020-01-02  950.56  937.85  953.10  937.85\n",
            "2020-01-03  934.59  946.50  950.46  932.40\n",
            "2020-01-06  904.27  933.90  933.90  902.20\n",
            "2020-01-07  909.57  912.50  926.50  906.50\n",
            "2020-01-08  914.55  897.10  916.68  896.16\n",
            "\n",
            "[437 rows x 4 columns]\n",
            "////\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld\n",
            "Date                                                         \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961\n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047\n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348\n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111\n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372\n",
            "...                  ...       ...       ...              ...\n",
            "2019-12-27      0.009908  0.005925  0.007927         0.005921\n",
            "2019-12-30     -0.000424  0.004299  0.010876         0.009908\n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424\n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864\n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587\n",
            "\n",
            "[427 rows x 4 columns]\n",
            "GARCH\n",
            "Date\n",
            "2018-04-10    1.694865\n",
            "2018-04-11    2.043275\n",
            "2018-04-12    1.823356\n",
            "2018-04-13    1.657847\n",
            "2018-04-16    1.811710\n",
            "                ...   \n",
            "2019-12-27    1.282947\n",
            "2019-12-30    1.321040\n",
            "2019-12-31    1.293798\n",
            "2020-01-01    1.305695\n",
            "2020-01-02    1.288079\n",
            "Name: cond_vol, Length: 427, dtype: float64\n",
            "---------\n",
            "GJR GARCH\n",
            "Date\n",
            "2018-04-10    1.686020\n",
            "2018-04-11    2.211677\n",
            "2018-04-12    1.976819\n",
            "2018-04-13    1.787919\n",
            "2018-04-16    1.997771\n",
            "                ...   \n",
            "2019-12-27    1.214483\n",
            "2019-12-30    1.222712\n",
            "2019-12-31    1.202605\n",
            "2020-01-01    1.232435\n",
            "2020-01-02    1.216648\n",
            "Name: cond_vol, Length: 427, dtype: float64\n",
            "---------\n",
            "T_ANN_ARCH_FIT Data_AR\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld  CV_GARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961  0.016949   \n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047  0.020433   \n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348  0.018234   \n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111  0.016578   \n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372  0.018117   \n",
            "...                  ...       ...       ...              ...       ...   \n",
            "2019-12-27      0.009908  0.005925  0.007927         0.005921  0.012829   \n",
            "2019-12-30     -0.000424  0.004299  0.010876         0.009908  0.013210   \n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424  0.012938   \n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864  0.013057   \n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587  0.012881   \n",
            "\n",
            "            CV_GJR_GARCH  CV_TARCH  CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                                                   \n",
            "2018-04-10      0.016860  0.013259   0.016894    0.013994    0.018386  \n",
            "2018-04-11      0.022117  0.018378   0.020714    0.018388    0.022154  \n",
            "2018-04-12      0.019768  0.016774   0.017612    0.015802    0.018419  \n",
            "2018-04-13      0.017879  0.015595   0.015571    0.014175    0.016818  \n",
            "2018-04-16      0.019978  0.018735   0.018033    0.016958    0.019046  \n",
            "...                  ...       ...        ...         ...         ...  \n",
            "2019-12-27      0.012145  0.011258   0.011498    0.011765    0.012157  \n",
            "2019-12-30      0.012227  0.011020   0.012368    0.012687    0.012624  \n",
            "2019-12-31      0.012026  0.010807   0.011719    0.012022    0.012097  \n",
            "2020-01-01      0.012324  0.011570   0.012094    0.012442    0.012297  \n",
            "2020-01-02      0.012166  0.011523   0.011729    0.012080    0.011971  \n",
            "\n",
            "[427 rows x 10 columns]\n",
            "==================\n",
            "XDATA_AR\n",
            "                  SD  DailyReturnsOld  CV_GARCH  CV_GJR_GARCH  CV_TARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-10  0.025391         0.013961  0.016949      0.016860  0.013259   \n",
            "2018-04-11  0.029296        -0.027047  0.020433      0.022117  0.018378   \n",
            "2018-04-12  0.024242         0.001348  0.018234      0.019768  0.016774   \n",
            "2018-04-13  0.015647         0.000111  0.016578      0.017879  0.015595   \n",
            "2018-04-16  0.016668        -0.019372  0.018117      0.019978  0.018735   \n",
            "...              ...              ...       ...           ...       ...   \n",
            "2019-12-27  0.005925         0.005921  0.012829      0.012145  0.011258   \n",
            "2019-12-30  0.004299         0.009908  0.013210      0.012227  0.011020   \n",
            "2019-12-31  0.004560        -0.000424  0.012938      0.012026  0.010807   \n",
            "2020-01-01  0.005910        -0.004864  0.013057      0.012324  0.011570   \n",
            "2020-01-02  0.005991        -0.001587  0.012881      0.012166  0.011523   \n",
            "\n",
            "            CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                           \n",
            "2018-04-10   0.016894    0.013994    0.018386  \n",
            "2018-04-11   0.020714    0.018388    0.022154  \n",
            "2018-04-12   0.017612    0.015802    0.018419  \n",
            "2018-04-13   0.015571    0.014175    0.016818  \n",
            "2018-04-16   0.018033    0.016958    0.019046  \n",
            "...               ...         ...         ...  \n",
            "2019-12-27   0.011498    0.011765    0.012157  \n",
            "2019-12-30   0.012368    0.012687    0.012624  \n",
            "2019-12-31   0.011719    0.012022    0.012097  \n",
            "2020-01-01   0.012094    0.012442    0.012297  \n",
            "2020-01-02   0.011729    0.012080    0.011971  \n",
            "\n",
            "[427 rows x 8 columns]\n",
            "YDATA_AR\n",
            "Date\n",
            "2018-04-10    0.016372\n",
            "2018-04-11    0.012233\n",
            "2018-04-12    0.013067\n",
            "2018-04-13    0.013197\n",
            "2018-04-16    0.012913\n",
            "                ...   \n",
            "2019-12-27    0.007927\n",
            "2019-12-30    0.010876\n",
            "2019-12-31    0.017420\n",
            "2020-01-01    0.018609\n",
            "2020-01-02    0.019322\n",
            "Name: TrueSD, Length: 427, dtype: float64\n",
            "Transformer DB features\n",
            "8\n",
            "For loop transformer db\n",
            "%%%%%%%%%%%%%%%%%%%\n",
            "[[[ 0.83564415  0.65591321 -0.34257916 ... -0.36801293 -0.95185237\n",
            "   -0.21785181]\n",
            "  [ 1.21576257 -1.46130748  0.22261115 ...  0.3203418  -0.10915428\n",
            "    0.32976459]\n",
            "  [ 0.72385817  0.00470697 -0.13414038 ... -0.23859247 -0.6051473\n",
            "   -0.21309961]\n",
            "  ...\n",
            "  [-0.36374258 -0.58414962 -0.51278318 ... -0.40736047 -0.48791273\n",
            "   -0.54499279]\n",
            "  [-0.35114043  0.06375521 -0.68495435 ... -0.74166122 -0.84443996\n",
            "   -0.75075835]\n",
            "  [-0.37874686 -1.02188356 -0.36009939 ... -0.28886178 -0.36326969\n",
            "   -0.35013653]]\n",
            "\n",
            " [[ 1.21576257 -1.46130748  0.22261115 ...  0.3203418  -0.10915428\n",
            "    0.32976459]\n",
            "  [ 0.72385817  0.00470697 -0.13414038 ... -0.23859247 -0.6051473\n",
            "   -0.21309961]\n",
            "  [-0.1126266  -0.05916092 -0.40262977 ... -0.60637493 -0.91712437\n",
            "   -0.44580472]\n",
            "  ...\n",
            "  [-0.35114043  0.06375521 -0.68495435 ... -0.74166122 -0.84443996\n",
            "   -0.75075835]\n",
            "  [-0.37874686 -1.02188356 -0.36009939 ... -0.28886178 -0.36326969\n",
            "   -0.35013653]\n",
            "  [-0.60561411  0.01027341 -0.57347703 ... -0.6858029  -0.79392418\n",
            "   -0.67878923]]\n",
            "\n",
            " [[ 0.72385817  0.00470697 -0.13414038 ... -0.23859247 -0.6051473\n",
            "   -0.21309961]\n",
            "  [-0.1126266  -0.05916092 -0.40262977 ... -0.60637493 -0.91712437\n",
            "   -0.44580472]\n",
            "  [-0.01324976 -1.06504137 -0.15303304 ... -0.16278094 -0.38344184\n",
            "   -0.12203586]\n",
            "  ...\n",
            "  [-0.37874686 -1.02188356 -0.36009939 ... -0.28886178 -0.36326969\n",
            "   -0.35013653]\n",
            "  [-0.60561411  0.01027341 -0.57347703 ... -0.6858029  -0.79392418\n",
            "   -0.67878923]\n",
            "  [-0.0405851   1.22189579 -0.15528967 ... -0.10433773 -0.19134115\n",
            "   -0.1556869 ]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.01603951  0.36941443 -0.82506029 ... -0.82839551 -0.86386006\n",
            "   -0.89619088]\n",
            "  [-1.19074039  0.3426339  -0.86065226 ... -0.87406636 -0.90671283\n",
            "   -0.9372034 ]\n",
            "  [-1.25390999 -0.05991261 -0.93358185 ... -1.08060483 -1.13558985\n",
            "   -1.02359119]\n",
            "  ...\n",
            "  [-1.05888958  0.24083444 -1.01079308 ... -1.34013153 -1.3792923\n",
            "   -1.12321258]\n",
            "  [-1.21706084  0.44666734 -0.94899818 ... -1.18343723 -1.20245056\n",
            "   -1.05536412]\n",
            "  [-1.19171776 -0.08675023 -0.9931911  ... -1.30037915 -1.33010584\n",
            "   -1.13195495]]\n",
            "\n",
            " [[-1.19074039  0.3426339  -0.86065226 ... -0.87406636 -0.90671283\n",
            "   -0.9372034 ]\n",
            "  [-1.25390999 -0.05991261 -0.93358185 ... -1.08060483 -1.13558985\n",
            "   -1.02359119]\n",
            "  [-0.9041613  -0.5736046  -0.82090592 ... -0.87904576 -0.91356254\n",
            "   -0.87925865]\n",
            "  ...\n",
            "  [-1.21706084  0.44666734 -0.94899818 ... -1.18343723 -1.20245056\n",
            "   -1.05536412]\n",
            "  [-1.19171776 -0.08675023 -0.9931911  ... -1.30037915 -1.33010584\n",
            "   -1.13195495]\n",
            "  [-1.06027407 -0.31599989 -0.97389143 ... -1.23286819 -1.24955007\n",
            "   -1.10290738]]\n",
            "\n",
            " [[-1.25390999 -0.05991261 -0.93358185 ... -1.08060483 -1.13558985\n",
            "   -1.02359119]\n",
            "  [-0.9041613  -0.5736046  -0.82090592 ... -0.87904576 -0.91356254\n",
            "   -0.87925865]\n",
            "  [-0.91410402 -0.01366559 -0.90782139 ... -1.11372782 -1.17552\n",
            "   -1.01803138]\n",
            "  ...\n",
            "  [-1.19171776 -0.08675023 -0.9931911  ... -1.30037915 -1.33010584\n",
            "   -1.13195495]\n",
            "  [-1.06027407 -0.31599989 -0.97389143 ... -1.23286819 -1.24955007\n",
            "   -1.10290738]\n",
            "  [-1.05246901 -0.14683747 -1.00246842 ... -1.29857349 -1.31889929\n",
            "   -1.15029489]]]\n",
            "$$$$$$$$$$$$$$$$$$\n",
            "[0.01658115 0.01644887 0.01392534 0.01422053 0.01229865 0.00972776\n",
            " 0.00867076 0.00892153 0.01207872 0.01647356 0.01615604 0.01500122\n",
            " 0.0167847  0.02261649 0.02360776 0.02452643 0.02698428 0.03263853\n",
            " 0.02838046 0.0310246  0.0321993  0.02819379 0.02367704 0.02396434\n",
            " 0.018583   0.02006291 0.01950072 0.02265231 0.02314761 0.01812537\n",
            " 0.00956141 0.01002206 0.00695038 0.00540218 0.00649334 0.00518429\n",
            " 0.00660587 0.00821767 0.00931347 0.01582522 0.01621642 0.01604295\n",
            " 0.01925161 0.02107853 0.00849757 0.0070789  0.01565774 0.01916478\n",
            " 0.01401718 0.01344408 0.01034613 0.00969791 0.01075147 0.01443171\n",
            " 0.01375368 0.01641316 0.01690522 0.01363059 0.01239572 0.02820727\n",
            " 0.02706274 0.03128517 0.03061225 0.02674777 0.0226456  0.01510742\n",
            " 0.01384968 0.01167405 0.01101683 0.00934521 0.0092174  0.00894502\n",
            " 0.00960887 0.00546016 0.00565788 0.01206904 0.01564281 0.01575449\n",
            " 0.01574223 0.01591303 0.01185865 0.00558475 0.00573126 0.00536756\n",
            " 0.00604959 0.00303584 0.00305214 0.0104105  0.01003649 0.01094347\n",
            " 0.01082301 0.01409711 0.01320463 0.02046955 0.01959908 0.02038922\n",
            " 0.02992722 0.03242985 0.02525232 0.03088863 0.03048972 0.01356763\n",
            " 0.02177392 0.02274166 0.0239988  0.02498421 0.02297674 0.01852934\n",
            " 0.01526768 0.01803843 0.01777994 0.02168908 0.05283721 0.06135608\n",
            " 0.05740498 0.06124139 0.06127047 0.04188313 0.0349393  0.02497693\n",
            " 0.0242276  0.03591097 0.02793336 0.02784666 0.02193783 0.0194116\n",
            " 0.00432954 0.00404744 0.01198148 0.01195197 0.01093781 0.0106387\n",
            " 0.00853092 0.01595972 0.01561462 0.01549642 0.01519679 0.01633771\n",
            " 0.00644136 0.00870514 0.01349936 0.01984896 0.01847835 0.02126085\n",
            " 0.0218874  0.0230764  0.01840597 0.01858194 0.0166817  0.0220642\n",
            " 0.02173743 0.02940537 0.03066572 0.03305737 0.03401424 0.0246027\n",
            " 0.02354677 0.01871444 0.01790165 0.02144812 0.02031551 0.02137692\n",
            " 0.02111941 0.02296861 0.01525515 0.01669552 0.01628707 0.0131568\n",
            " 0.01382618 0.01368438 0.01115956 0.01118074 0.01091927 0.00487038\n",
            " 0.00532377 0.00470857 0.00471091 0.01142992 0.01144337 0.01413047\n",
            " 0.01600479 0.01969938 0.01666903 0.01707246 0.01630034 0.0152526\n",
            " 0.02144472 0.02751147 0.02673544 0.0278577  0.02815695 0.0207339\n",
            " 0.01227964 0.02133929 0.01665654 0.01826685 0.01816911 0.01820562\n",
            " 0.00960425 0.00909611 0.00899242 0.01187913 0.01523953 0.01519298\n",
            " 0.0192084  0.01891998 0.010463   0.0105996  0.01360099 0.01103831\n",
            " 0.01236519 0.0108059  0.00890935 0.00803958 0.00808686 0.01050686\n",
            " 0.01009772 0.01024592 0.00896467 0.00973217 0.00502041 0.0060571\n",
            " 0.00651612 0.00624908 0.00700831 0.00652003 0.00618053 0.00629767\n",
            " 0.0083634  0.00900904 0.01003294 0.00901974 0.01220903 0.01217357\n",
            " 0.01332609 0.01169683 0.00924914 0.00932588 0.00987151 0.00909439\n",
            " 0.0093536  0.00975013 0.00798102 0.00828214 0.01189389 0.01147718\n",
            " 0.01142665 0.01668842 0.01694362 0.01458934 0.01472795 0.01524071\n",
            " 0.0162221  0.01822313 0.01773328 0.01651045 0.01680327 0.01148143\n",
            " 0.01312327 0.02060673 0.01746681 0.02015685 0.02127158 0.02917684\n",
            " 0.02133082 0.01629192 0.01676039 0.01650755 0.01064498 0.00890362\n",
            " 0.01211514 0.01062052 0.01637348 0.01600519 0.0167101  0.01397077\n",
            " 0.01393007 0.00737196 0.00799769 0.00707274 0.01133755 0.01126958\n",
            " 0.01417131 0.01357984 0.01090321 0.00968406 0.00991858 0.00507851\n",
            " 0.00587077 0.00470996 0.00608701 0.00637849 0.00841441 0.00921439\n",
            " 0.04682072 0.05338705 0.05321183 0.05143143 0.0534651  0.02158339\n",
            " 0.01744301 0.01068289 0.01057116 0.02073705 0.03045701 0.0253212\n",
            " 0.02406746 0.02221231 0.04645246 0.03958041 0.03960738 0.0390337\n",
            " 0.03185376 0.0068513  0.00507705 0.00972455 0.0102742  0.01250509\n",
            " 0.014914   0.03425918 0.03915376 0.03923513 0.03919975 0.0368963\n",
            " 0.02558971 0.02179359 0.02575863 0.03723891 0.03654392 0.03655854\n",
            " 0.02400689 0.02433664 0.01385381 0.01370793 0.01260864 0.01605885\n",
            " 0.01619339 0.01260894 0.01450524 0.01329494 0.01464124 0.01314022\n",
            " 0.01550848 0.01557534 0.03577498 0.04334804 0.04073104 0.0421828\n",
            " 0.03761028 0.03263566 0.01289557 0.01278992 0.01308288 0.00987416\n",
            " 0.00612695 0.01090542 0.01173132 0.0115287  0.01029979 0.01001886\n",
            " 0.01013492 0.01382568 0.01411854 0.02056842 0.02080767 0.01992447\n",
            " 0.01551982 0.01647635 0.01202702 0.0127616  0.0130478  0.01482056\n",
            " 0.01848161 0.01846184 0.01841059 0.01835362 0.01787742 0.00949392\n",
            " 0.00766571 0.00463801 0.00555199 0.00419528 0.00380534 0.00671555\n",
            " 0.00563002 0.00567708 0.00885541 0.00907483 0.00935302 0.00888578\n",
            " 0.01207091 0.01193044 0.01503192 0.01340349 0.01304874 0.01282505\n",
            " 0.01196085 0.00809172 0.01185992 0.01132837 0.00636772 0.0063649\n",
            " 0.00456988 0.00392083 0.00751442 0.00741226 0.00645107 0.00488504\n",
            " 0.00592462 0.00429945 0.00455984 0.0059104  0.00599059 0.0079265\n",
            " 0.01087642 0.01741999 0.01860908 0.01932189]\n",
            "Transformer DB features\n",
            "8\n",
            "14/14 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-07c24de7141f>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ResultsCollection=ResultsCollection.append(IterResults, ignore_index=True)\n",
            "\r  0%|          | 2/744 [00:27<2:47:47, 13.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results\n",
            "{'Date_Forecast': datetime.date(2020, 1, 3), 'Forecast_T_ANN_ARCH': 0.024037132, 'Forecast_GARCH': 0.01906728381266931, 'Forecast_GJR_GARCH': 0.0157134291513537, 'Forecast_TARCH': 0.012941983951159594, 'Forecast_EGARCH': 0.017746045738304267, 'Forecast_AVGARCH': 0.018602606084341923, 'Forecast_FIGARCH': 0.017538255383240123, 'ReturnForecast': -0.01694335416295356, 'TrueSD': 0.023113983139057513, 'VaR_T_ANN_ARCH': 0.07699841338047278, 'VaR_GARCH': 0.04247906725466577, 'VaR_GJR_GARCH': 0.03829094079840305, 'VaR_TARCH': 0.03477286788630978, 'VaR_EGARCH': 0.04096249174831756, 'VaR_AVGARCH': 0.04204843678970008, 'VaR_FIGARCH': 0.04130085747541155}\n",
            "             Price    Open    High     Low\n",
            "Date                                      \n",
            "2018-04-02  526.74  507.50  529.50  507.12\n",
            "2018-04-03  538.16  526.90  541.85  523.26\n",
            "2018-04-04  522.86  542.00  544.56  520.28\n",
            "2018-04-05  544.38  533.30  550.00  531.50\n",
            "2018-04-06  548.42  546.33  551.39  541.50\n",
            "...            ...     ...     ...     ...\n",
            "2020-01-03  934.59  946.50  950.46  932.40\n",
            "2020-01-06  904.27  933.90  933.90  902.20\n",
            "2020-01-07  909.57  912.50  926.50  906.50\n",
            "2020-01-08  914.55  897.10  916.68  896.16\n",
            "2020-01-09  939.52  949.99  949.99  920.90\n",
            "\n",
            "[438 rows x 4 columns]\n",
            "////\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld\n",
            "Date                                                         \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961\n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047\n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348\n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111\n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372\n",
            "...                  ...       ...       ...              ...\n",
            "2019-12-30     -0.000424  0.004299  0.010876         0.009908\n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424\n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864\n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587\n",
            "2020-01-03     -0.016943  0.007927  0.023114         0.013461\n",
            "\n",
            "[428 rows x 4 columns]\n",
            "GARCH\n",
            "Date\n",
            "2018-04-10    1.696582\n",
            "2018-04-11    2.044531\n",
            "2018-04-12    1.821814\n",
            "2018-04-13    1.656251\n",
            "2018-04-16    1.811138\n",
            "                ...   \n",
            "2019-12-30    1.338431\n",
            "2019-12-31    1.310792\n",
            "2020-01-01    1.321870\n",
            "2020-01-02    1.304201\n",
            "2020-01-03    1.398009\n",
            "Name: cond_vol, Length: 428, dtype: float64\n",
            "---------\n",
            "GJR GARCH\n",
            "Date\n",
            "2018-04-10    1.689751\n",
            "2018-04-11    2.221867\n",
            "2018-04-12    1.975290\n",
            "2018-04-13    1.780452\n",
            "2018-04-16    1.995184\n",
            "                ...   \n",
            "2019-12-30    1.248694\n",
            "2019-12-31    1.228583\n",
            "2020-01-01    1.257876\n",
            "2020-01-02    1.241838\n",
            "2020-01-03    1.281782\n",
            "Name: cond_vol, Length: 428, dtype: float64\n",
            "---------\n",
            "T_ANN_ARCH_FIT Data_AR\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld  CV_GARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961  0.016966   \n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047  0.020445   \n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348  0.018218   \n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111  0.016563   \n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372  0.018111   \n",
            "...                  ...       ...       ...              ...       ...   \n",
            "2019-12-30     -0.000424  0.004299  0.010876         0.009908  0.013384   \n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424  0.013108   \n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864  0.013219   \n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587  0.013042   \n",
            "2020-01-03     -0.016943  0.007927  0.023114         0.013461  0.013980   \n",
            "\n",
            "            CV_GJR_GARCH  CV_TARCH  CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                                                   \n",
            "2018-04-10      0.016898  0.013297   0.016922    0.014055    0.018396  \n",
            "2018-04-11      0.022219  0.018426   0.020793    0.018477    0.022179  \n",
            "2018-04-12      0.019753  0.016825   0.017594    0.015835    0.018341  \n",
            "2018-04-13      0.017805  0.015643   0.015526    0.014195    0.016741  \n",
            "2018-04-16      0.019952  0.018782   0.018056    0.017006    0.019037  \n",
            "...                  ...       ...        ...         ...         ...  \n",
            "2019-12-30      0.012487  0.011227   0.012602    0.012885    0.012837  \n",
            "2019-12-31      0.012286  0.011014   0.011923    0.012189    0.012292  \n",
            "2020-01-01      0.012579  0.011778   0.012294    0.012599    0.012481  \n",
            "2020-01-02      0.012418  0.011729   0.011913    0.012223    0.012152  \n",
            "2020-01-03      0.012818  0.011596   0.013565    0.013822    0.013449  \n",
            "\n",
            "[428 rows x 10 columns]\n",
            "==================\n",
            "XDATA_AR\n",
            "                  SD  DailyReturnsOld  CV_GARCH  CV_GJR_GARCH  CV_TARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-10  0.025391         0.013961  0.016966      0.016898  0.013297   \n",
            "2018-04-11  0.029296        -0.027047  0.020445      0.022219  0.018426   \n",
            "2018-04-12  0.024242         0.001348  0.018218      0.019753  0.016825   \n",
            "2018-04-13  0.015647         0.000111  0.016563      0.017805  0.015643   \n",
            "2018-04-16  0.016668        -0.019372  0.018111      0.019952  0.018782   \n",
            "...              ...              ...       ...           ...       ...   \n",
            "2019-12-30  0.004299         0.009908  0.013384      0.012487  0.011227   \n",
            "2019-12-31  0.004560        -0.000424  0.013108      0.012286  0.011014   \n",
            "2020-01-01  0.005910        -0.004864  0.013219      0.012579  0.011778   \n",
            "2020-01-02  0.005991        -0.001587  0.013042      0.012418  0.011729   \n",
            "2020-01-03  0.007927         0.013461  0.013980      0.012818  0.011596   \n",
            "\n",
            "            CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                           \n",
            "2018-04-10   0.016922    0.014055    0.018396  \n",
            "2018-04-11   0.020793    0.018477    0.022179  \n",
            "2018-04-12   0.017594    0.015835    0.018341  \n",
            "2018-04-13   0.015526    0.014195    0.016741  \n",
            "2018-04-16   0.018056    0.017006    0.019037  \n",
            "...               ...         ...         ...  \n",
            "2019-12-30   0.012602    0.012885    0.012837  \n",
            "2019-12-31   0.011923    0.012189    0.012292  \n",
            "2020-01-01   0.012294    0.012599    0.012481  \n",
            "2020-01-02   0.011913    0.012223    0.012152  \n",
            "2020-01-03   0.013565    0.013822    0.013449  \n",
            "\n",
            "[428 rows x 8 columns]\n",
            "YDATA_AR\n",
            "Date\n",
            "2018-04-10    0.016372\n",
            "2018-04-11    0.012233\n",
            "2018-04-12    0.013067\n",
            "2018-04-13    0.013197\n",
            "2018-04-16    0.012913\n",
            "                ...   \n",
            "2019-12-30    0.010876\n",
            "2019-12-31    0.017420\n",
            "2020-01-01    0.018609\n",
            "2020-01-02    0.019322\n",
            "2020-01-03    0.023114\n",
            "Name: TrueSD, Length: 428, dtype: float64\n",
            "Transformer DB features\n",
            "8\n",
            "For loop transformer db\n",
            "%%%%%%%%%%%%%%%%%%%\n",
            "[[[ 0.83791277  0.65490311 -0.34100892 ... -0.36422524 -0.95031509\n",
            "   -0.21965903]\n",
            "  [ 1.21814454 -1.46381276  0.23120276 ...  0.34130112 -0.08985132\n",
            "    0.33681821]\n",
            "  [ 0.72609346  0.00323699 -0.13506115 ... -0.24168656 -0.60390521\n",
            "   -0.22765626]\n",
            "  ...\n",
            "  [-0.36183163 -0.58603545 -0.51256221 ... -0.40299247 -0.47989367\n",
            "   -0.54966835]\n",
            "  [-0.34922572  0.06232693 -0.68446133 ... -0.74088226 -0.83975434\n",
            "   -0.75547829]\n",
            "  [-0.37684039 -1.02407852 -0.35455711 ... -0.27392112 -0.34956016\n",
            "   -0.34524988]]\n",
            "\n",
            " [[ 1.21814454 -1.46381276  0.23120276 ...  0.34130112 -0.08985132\n",
            "    0.33681821]\n",
            "  [ 0.72609346  0.00323699 -0.13506115 ... -0.24168656 -0.60390521\n",
            "   -0.22765626]\n",
            "  [-0.11064076 -0.06067601 -0.40733448 ... -0.61871789 -0.92311972\n",
            "   -0.46294254]\n",
            "  ...\n",
            "  [-0.34922572  0.06232693 -0.68446133 ... -0.74088226 -0.83975434\n",
            "   -0.75547829]\n",
            "  [-0.37684039 -1.02407852 -0.35455711 ... -0.27392112 -0.34956016\n",
            "   -0.34524988]\n",
            "  [-0.60377529  0.00880736 -0.57092979 ... -0.68046994 -0.78758404\n",
            "   -0.68336605]]\n",
            "\n",
            " [[ 0.72609346  0.00323699 -0.13506115 ... -0.24168656 -0.60390521\n",
            "   -0.22765626]\n",
            "  [-0.11064076 -0.06067601 -0.40733448 ... -0.61871789 -0.92311972\n",
            "   -0.46294254]\n",
            "  [-0.01123429 -1.0672668  -0.1526178  ... -0.1575669  -0.37602674\n",
            "   -0.12524231]\n",
            "  ...\n",
            "  [-0.37684039 -1.02407852 -0.35455711 ... -0.27392112 -0.34956016\n",
            "   -0.34524988]\n",
            "  [-0.60377529  0.00880736 -0.57092979 ... -0.68046994 -0.78758404\n",
            "   -0.68336605]\n",
            "  [-0.03857778  1.22128539 -0.14099739 ... -0.07497924 -0.16695118\n",
            "   -0.14171298]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.18907606  0.34140256 -0.8463846  ... -0.85337392 -0.88946402\n",
            "   -0.92321356]\n",
            "  [-1.2522645  -0.06142823 -0.91989359 ... -1.06802658 -1.12723218\n",
            "   -1.01092974]\n",
            "  [-0.90241151 -0.57548299 -0.80754559 ... -0.8608858  -0.90141881\n",
            "   -0.86604585]\n",
            "  ...\n",
            "  [-1.21540436  0.44550947 -0.92999964 ... -1.15163961 -1.17798587\n",
            "   -1.03715999]\n",
            "  [-1.19005372 -0.0882848  -0.97545344 ... -1.27541198 -1.31334657\n",
            "   -1.1173646 ]\n",
            "  [-1.05857083 -0.31769635 -0.95723526 ... -1.20781402 -1.23353764\n",
            "   -1.0895681 ]]\n",
            "\n",
            " [[-1.2522645  -0.06142823 -0.91989359 ... -1.06802658 -1.12723218\n",
            "   -1.01092974]\n",
            "  [-0.90241151 -0.57548299 -0.80754559 ... -0.8608858  -0.90141881\n",
            "   -0.86604585]\n",
            "  [-0.9123572  -0.01514854 -0.89501241 ... -1.10371149 -1.17147529\n",
            "   -1.00720794]\n",
            "  ...\n",
            "  [-1.19005372 -0.0882848  -0.97545344 ... -1.27541198 -1.31334657\n",
            "   -1.1173646 ]\n",
            "  [-1.05857083 -0.31769635 -0.95723526 ... -1.20781402 -1.23353764\n",
            "   -1.0895681 ]\n",
            "  [-1.05076345 -0.14841447 -0.98629103 ... -1.27718442 -1.30681707\n",
            "   -1.13786931]]\n",
            "\n",
            " [[-0.90241151 -0.57548299 -0.80754559 ... -0.8608858  -0.90141881\n",
            "   -0.86604585]\n",
            "  [-0.9123572  -0.01514854 -0.89501241 ... -1.10371149 -1.17147529\n",
            "   -1.00720794]\n",
            "  [-1.00593324  0.06705267 -0.95468767 ... -1.25953466 -1.33184635\n",
            "   -1.06481733]\n",
            "  ...\n",
            "  [-1.05857083 -0.31769635 -0.95723526 ... -1.20781402 -1.23353764\n",
            "   -1.0895681 ]\n",
            "  [-1.05076345 -0.14841447 -0.98629103 ... -1.27718442 -1.30681707\n",
            "   -1.13786931]\n",
            "  [-0.86229313  0.62910087 -0.83202109 ... -0.97607261 -0.99561764\n",
            "   -0.94710521]]]\n",
            "$$$$$$$$$$$$$$$$$$\n",
            "[0.01658115 0.01644887 0.01392534 0.01422053 0.01229865 0.00972776\n",
            " 0.00867076 0.00892153 0.01207872 0.01647356 0.01615604 0.01500122\n",
            " 0.0167847  0.02261649 0.02360776 0.02452643 0.02698428 0.03263853\n",
            " 0.02838046 0.0310246  0.0321993  0.02819379 0.02367704 0.02396434\n",
            " 0.018583   0.02006291 0.01950072 0.02265231 0.02314761 0.01812537\n",
            " 0.00956141 0.01002206 0.00695038 0.00540218 0.00649334 0.00518429\n",
            " 0.00660587 0.00821767 0.00931347 0.01582522 0.01621642 0.01604295\n",
            " 0.01925161 0.02107853 0.00849757 0.0070789  0.01565774 0.01916478\n",
            " 0.01401718 0.01344408 0.01034613 0.00969791 0.01075147 0.01443171\n",
            " 0.01375368 0.01641316 0.01690522 0.01363059 0.01239572 0.02820727\n",
            " 0.02706274 0.03128517 0.03061225 0.02674777 0.0226456  0.01510742\n",
            " 0.01384968 0.01167405 0.01101683 0.00934521 0.0092174  0.00894502\n",
            " 0.00960887 0.00546016 0.00565788 0.01206904 0.01564281 0.01575449\n",
            " 0.01574223 0.01591303 0.01185865 0.00558475 0.00573126 0.00536756\n",
            " 0.00604959 0.00303584 0.00305214 0.0104105  0.01003649 0.01094347\n",
            " 0.01082301 0.01409711 0.01320463 0.02046955 0.01959908 0.02038922\n",
            " 0.02992722 0.03242985 0.02525232 0.03088863 0.03048972 0.01356763\n",
            " 0.02177392 0.02274166 0.0239988  0.02498421 0.02297674 0.01852934\n",
            " 0.01526768 0.01803843 0.01777994 0.02168908 0.05283721 0.06135608\n",
            " 0.05740498 0.06124139 0.06127047 0.04188313 0.0349393  0.02497693\n",
            " 0.0242276  0.03591097 0.02793336 0.02784666 0.02193783 0.0194116\n",
            " 0.00432954 0.00404744 0.01198148 0.01195197 0.01093781 0.0106387\n",
            " 0.00853092 0.01595972 0.01561462 0.01549642 0.01519679 0.01633771\n",
            " 0.00644136 0.00870514 0.01349936 0.01984896 0.01847835 0.02126085\n",
            " 0.0218874  0.0230764  0.01840597 0.01858194 0.0166817  0.0220642\n",
            " 0.02173743 0.02940537 0.03066572 0.03305737 0.03401424 0.0246027\n",
            " 0.02354677 0.01871444 0.01790165 0.02144812 0.02031551 0.02137692\n",
            " 0.02111941 0.02296861 0.01525515 0.01669552 0.01628707 0.0131568\n",
            " 0.01382618 0.01368438 0.01115956 0.01118074 0.01091927 0.00487038\n",
            " 0.00532377 0.00470857 0.00471091 0.01142992 0.01144337 0.01413047\n",
            " 0.01600479 0.01969938 0.01666903 0.01707246 0.01630034 0.0152526\n",
            " 0.02144472 0.02751147 0.02673544 0.0278577  0.02815695 0.0207339\n",
            " 0.01227964 0.02133929 0.01665654 0.01826685 0.01816911 0.01820562\n",
            " 0.00960425 0.00909611 0.00899242 0.01187913 0.01523953 0.01519298\n",
            " 0.0192084  0.01891998 0.010463   0.0105996  0.01360099 0.01103831\n",
            " 0.01236519 0.0108059  0.00890935 0.00803958 0.00808686 0.01050686\n",
            " 0.01009772 0.01024592 0.00896467 0.00973217 0.00502041 0.0060571\n",
            " 0.00651612 0.00624908 0.00700831 0.00652003 0.00618053 0.00629767\n",
            " 0.0083634  0.00900904 0.01003294 0.00901974 0.01220903 0.01217357\n",
            " 0.01332609 0.01169683 0.00924914 0.00932588 0.00987151 0.00909439\n",
            " 0.0093536  0.00975013 0.00798102 0.00828214 0.01189389 0.01147718\n",
            " 0.01142665 0.01668842 0.01694362 0.01458934 0.01472795 0.01524071\n",
            " 0.0162221  0.01822313 0.01773328 0.01651045 0.01680327 0.01148143\n",
            " 0.01312327 0.02060673 0.01746681 0.02015685 0.02127158 0.02917684\n",
            " 0.02133082 0.01629192 0.01676039 0.01650755 0.01064498 0.00890362\n",
            " 0.01211514 0.01062052 0.01637348 0.01600519 0.0167101  0.01397077\n",
            " 0.01393007 0.00737196 0.00799769 0.00707274 0.01133755 0.01126958\n",
            " 0.01417131 0.01357984 0.01090321 0.00968406 0.00991858 0.00507851\n",
            " 0.00587077 0.00470996 0.00608701 0.00637849 0.00841441 0.00921439\n",
            " 0.04682072 0.05338705 0.05321183 0.05143143 0.0534651  0.02158339\n",
            " 0.01744301 0.01068289 0.01057116 0.02073705 0.03045701 0.0253212\n",
            " 0.02406746 0.02221231 0.04645246 0.03958041 0.03960738 0.0390337\n",
            " 0.03185376 0.0068513  0.00507705 0.00972455 0.0102742  0.01250509\n",
            " 0.014914   0.03425918 0.03915376 0.03923513 0.03919975 0.0368963\n",
            " 0.02558971 0.02179359 0.02575863 0.03723891 0.03654392 0.03655854\n",
            " 0.02400689 0.02433664 0.01385381 0.01370793 0.01260864 0.01605885\n",
            " 0.01619339 0.01260894 0.01450524 0.01329494 0.01464124 0.01314022\n",
            " 0.01550848 0.01557534 0.03577498 0.04334804 0.04073104 0.0421828\n",
            " 0.03761028 0.03263566 0.01289557 0.01278992 0.01308288 0.00987416\n",
            " 0.00612695 0.01090542 0.01173132 0.0115287  0.01029979 0.01001886\n",
            " 0.01013492 0.01382568 0.01411854 0.02056842 0.02080767 0.01992447\n",
            " 0.01551982 0.01647635 0.01202702 0.0127616  0.0130478  0.01482056\n",
            " 0.01848161 0.01846184 0.01841059 0.01835362 0.01787742 0.00949392\n",
            " 0.00766571 0.00463801 0.00555199 0.00419528 0.00380534 0.00671555\n",
            " 0.00563002 0.00567708 0.00885541 0.00907483 0.00935302 0.00888578\n",
            " 0.01207091 0.01193044 0.01503192 0.01340349 0.01304874 0.01282505\n",
            " 0.01196085 0.00809172 0.01185992 0.01132837 0.00636772 0.0063649\n",
            " 0.00456988 0.00392083 0.00751442 0.00741226 0.00645107 0.00488504\n",
            " 0.00592462 0.00429945 0.00455984 0.0059104  0.00599059 0.0079265\n",
            " 0.01087642 0.01741999 0.01860908 0.01932189 0.02311398]\n",
            "Transformer DB features\n",
            "8\n",
            "14/14 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-07c24de7141f>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ResultsCollection=ResultsCollection.append(IterResults, ignore_index=True)\n",
            "\r  0%|          | 3/744 [00:40<2:43:36, 13.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results\n",
            "{'Date_Forecast': datetime.date(2020, 1, 6), 'Forecast_T_ANN_ARCH': 0.02639293, 'Forecast_GARCH': 0.02545453581396451, 'Forecast_GJR_GARCH': 0.02599097183336615, 'Forecast_TARCH': 0.02201615391398573, 'Forecast_EGARCH': 0.02617642785915914, 'Forecast_AVGARCH': 0.026381171558360596, 'Forecast_FIGARCH': 0.0251030559085133, 'ReturnForecast': -0.03297994207970145, 'TrueSD': 0.021688743684035155, 'VaR_T_ANN_ARCH': 0.08463939980184786, 'VaR_GARCH': 0.049328717096309156, 'VaR_GJR_GARCH': 0.04964060124629551, 'VaR_TARCH': 0.045683199565355624, 'VaR_EGARCH': 0.05008355042959138, 'VaR_AVGARCH': 0.05036117405573612, 'VaR_FIGARCH': 0.04978002664513359}\n",
            "             Price    Open    High     Low\n",
            "Date                                      \n",
            "2018-04-02  526.74  507.50  529.50  507.12\n",
            "2018-04-03  538.16  526.90  541.85  523.26\n",
            "2018-04-04  522.86  542.00  544.56  520.28\n",
            "2018-04-05  544.38  533.30  550.00  531.50\n",
            "2018-04-06  548.42  546.33  551.39  541.50\n",
            "...            ...     ...     ...     ...\n",
            "2020-01-06  904.27  933.90  933.90  902.20\n",
            "2020-01-07  909.57  912.50  926.50  906.50\n",
            "2020-01-08  914.55  897.10  916.68  896.16\n",
            "2020-01-09  939.52  949.99  949.99  920.90\n",
            "2020-01-10  937.23  937.51  943.49  933.83\n",
            "\n",
            "[439 rows x 4 columns]\n",
            "////\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld\n",
            "Date                                                         \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961\n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047\n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348\n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111\n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372\n",
            "...                  ...       ...       ...              ...\n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424\n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864\n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587\n",
            "2020-01-03     -0.016943  0.007927  0.023114         0.013461\n",
            "2020-01-06     -0.032980  0.010876  0.021689        -0.016943\n",
            "\n",
            "[429 rows x 4 columns]\n",
            "GARCH\n",
            "Date\n",
            "2018-04-10    1.704779\n",
            "2018-04-11    2.068548\n",
            "2018-04-12    1.830744\n",
            "2018-04-13    1.658678\n",
            "2018-04-16    1.824429\n",
            "                ...   \n",
            "2019-12-31    1.336325\n",
            "2020-01-01    1.347580\n",
            "2020-01-02    1.329256\n",
            "2020-01-03    1.427577\n",
            "2020-01-06    1.627874\n",
            "Name: cond_vol, Length: 429, dtype: float64\n",
            "---------\n",
            "GJR GARCH\n",
            "Date\n",
            "2018-04-10    1.701937\n",
            "2018-04-11    2.284298\n",
            "2018-04-12    1.996384\n",
            "2018-04-13    1.777371\n",
            "2018-04-16    2.019961\n",
            "                ...   \n",
            "2019-12-31    1.256164\n",
            "2020-01-01    1.288705\n",
            "2020-01-02    1.271001\n",
            "2020-01-03    1.316438\n",
            "2020-01-06    1.670241\n",
            "Name: cond_vol, Length: 429, dtype: float64\n",
            "---------\n",
            "T_ANN_ARCH_FIT Data_AR\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld  CV_GARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-10     -0.027047  0.025391  0.016372         0.013961  0.017048   \n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047  0.020685   \n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348  0.018307   \n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111  0.016587   \n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372  0.018244   \n",
            "...                  ...       ...       ...              ...       ...   \n",
            "2019-12-31     -0.004864  0.004560  0.017420        -0.000424  0.013363   \n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864  0.013476   \n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587  0.013293   \n",
            "2020-01-03     -0.016943  0.007927  0.023114         0.013461  0.014276   \n",
            "2020-01-06     -0.032980  0.010876  0.021689        -0.016943  0.016279   \n",
            "\n",
            "            CV_GJR_GARCH  CV_TARCH  CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                                                   \n",
            "2018-04-10      0.017019  0.013521   0.017002    0.014208    0.018561  \n",
            "2018-04-11      0.022843  0.019259   0.021107    0.018814    0.022519  \n",
            "2018-04-12      0.019964  0.017237   0.017662    0.016004    0.018402  \n",
            "2018-04-13      0.017774  0.015774   0.015505    0.014291    0.016730  \n",
            "2018-04-16      0.020200  0.019252   0.018245    0.017240    0.019221  \n",
            "...                  ...       ...        ...         ...         ...  \n",
            "2019-12-31      0.012562  0.011162   0.012218    0.012444    0.012525  \n",
            "2020-01-01      0.012887  0.012029   0.012613    0.012868    0.012723  \n",
            "2020-01-02      0.012710  0.011949   0.012208    0.012467    0.012384  \n",
            "2020-01-03      0.013164  0.011971   0.013977    0.014155    0.013756  \n",
            "2020-01-06      0.016702  0.015579   0.016673    0.016629    0.016204  \n",
            "\n",
            "[429 rows x 10 columns]\n",
            "==================\n",
            "XDATA_AR\n",
            "                  SD  DailyReturnsOld  CV_GARCH  CV_GJR_GARCH  CV_TARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-10  0.025391         0.013961  0.017048      0.017019  0.013521   \n",
            "2018-04-11  0.029296        -0.027047  0.020685      0.022843  0.019259   \n",
            "2018-04-12  0.024242         0.001348  0.018307      0.019964  0.017237   \n",
            "2018-04-13  0.015647         0.000111  0.016587      0.017774  0.015774   \n",
            "2018-04-16  0.016668        -0.019372  0.018244      0.020200  0.019252   \n",
            "...              ...              ...       ...           ...       ...   \n",
            "2019-12-31  0.004560        -0.000424  0.013363      0.012562  0.011162   \n",
            "2020-01-01  0.005910        -0.004864  0.013476      0.012887  0.012029   \n",
            "2020-01-02  0.005991        -0.001587  0.013293      0.012710  0.011949   \n",
            "2020-01-03  0.007927         0.013461  0.014276      0.013164  0.011971   \n",
            "2020-01-06  0.010876        -0.016943  0.016279      0.016702  0.015579   \n",
            "\n",
            "            CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                           \n",
            "2018-04-10   0.017002    0.014208    0.018561  \n",
            "2018-04-11   0.021107    0.018814    0.022519  \n",
            "2018-04-12   0.017662    0.016004    0.018402  \n",
            "2018-04-13   0.015505    0.014291    0.016730  \n",
            "2018-04-16   0.018245    0.017240    0.019221  \n",
            "...               ...         ...         ...  \n",
            "2019-12-31   0.012218    0.012444    0.012525  \n",
            "2020-01-01   0.012613    0.012868    0.012723  \n",
            "2020-01-02   0.012208    0.012467    0.012384  \n",
            "2020-01-03   0.013977    0.014155    0.013756  \n",
            "2020-01-06   0.016673    0.016629    0.016204  \n",
            "\n",
            "[429 rows x 8 columns]\n",
            "YDATA_AR\n",
            "Date\n",
            "2018-04-10    0.016372\n",
            "2018-04-11    0.012233\n",
            "2018-04-12    0.013067\n",
            "2018-04-13    0.013197\n",
            "2018-04-16    0.012913\n",
            "                ...   \n",
            "2019-12-31    0.017420\n",
            "2020-01-01    0.018609\n",
            "2020-01-02    0.019322\n",
            "2020-01-03    0.023114\n",
            "2020-01-06    0.021689\n",
            "Name: TrueSD, Length: 429, dtype: float64\n",
            "Transformer DB features\n",
            "8\n",
            "For loop transformer db\n",
            "%%%%%%%%%%%%%%%%%%%\n",
            "[[[ 0.8399095   0.6571866  -0.34266538 ... -0.36378187 -0.94025266\n",
            "   -0.21254257]\n",
            "  [ 1.22043854 -1.46181351  0.25510259 ...  0.37880709 -0.04147313\n",
            "    0.36532564]\n",
            "  [ 0.72800276  0.00543306 -0.13567112 ... -0.24437297 -0.58983477\n",
            "   -0.2358394 ]\n",
            "  ...\n",
            "  [-0.3607729  -0.58391844 -0.51225421 ... -0.39496099 -0.46380567\n",
            "   -0.54891411]\n",
            "  [-0.34815714  0.06453092 -0.68634402 ... -0.74238535 -0.83677108\n",
            "   -0.75839098]\n",
            "  [-0.37579339 -1.02202028 -0.33760326 ... -0.24403883 -0.32246112\n",
            "   -0.32448449]]\n",
            "\n",
            " [[ 1.22043854 -1.46181351  0.25510259 ...  0.37880709 -0.04147313\n",
            "    0.36532564]\n",
            "  [ 0.72800276  0.00543306 -0.13567112 ... -0.24437297 -0.58983477\n",
            "   -0.2358394 ]\n",
            "  [-0.10938565 -0.05848852 -0.41841977 ... -0.63467783 -0.92397533\n",
            "   -0.47994008]\n",
            "  ...\n",
            "  [-0.34815714  0.06453092 -0.68634402 ... -0.74238535 -0.83677108\n",
            "   -0.75839098]\n",
            "  [-0.37579339 -1.02202028 -0.33760326 ... -0.24403883 -0.32246112\n",
            "   -0.32448449]\n",
            "  [-0.60290572  0.01100417 -0.56474091 ... -0.67089912 -0.78122456\n",
            "   -0.68050735]]\n",
            "\n",
            " [[ 0.72800276  0.00543306 -0.13567112 ... -0.24437297 -0.58983477\n",
            "   -0.2358394 ]\n",
            "  [-0.10938565 -0.05848852 -0.41841977 ... -0.63467783 -0.92397533\n",
            "   -0.47994008]\n",
            "  [-0.00990146 -1.06521435 -0.14604847 ... -0.13886252 -0.34856543\n",
            "   -0.11620209]\n",
            "  ...\n",
            "  [-0.37579339 -1.02202028 -0.33760326 ... -0.24403883 -0.32246112\n",
            "   -0.32448449]\n",
            "  [-0.60290572  0.01100417 -0.56474091 ... -0.67089912 -0.78122456\n",
            "   -0.68050735]\n",
            "  [-0.03726632  1.22364486 -0.11193051 ... -0.02715484 -0.12734947\n",
            "   -0.11059069]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-1.25190194 -0.05924084 -0.90170169 ... -1.05024807 -1.11968141\n",
            "   -0.99587411]\n",
            "  [-0.90177542 -0.57336456 -0.78386409 ... -0.82711113 -0.87989986\n",
            "   -0.84322508]\n",
            "  [-0.91172889 -0.01295495 -0.87441747 ... -1.08076067 -1.16272543\n",
            "   -0.99008345]\n",
            "  ...\n",
            "  [-1.18964252 -0.08610102 -0.94812996 ... -1.22918191 -1.28448014\n",
            "   -1.09387295]\n",
            "  [-1.05805683 -0.31554334 -0.92963508 ... -1.15770873 -1.20178347\n",
            "   -1.06486896]\n",
            "  [-1.05024335 -0.14623875 -0.9597456  ... -1.23094786 -1.28007815\n",
            "   -1.11444289]]\n",
            "\n",
            " [[-0.90177542 -0.57336456 -0.78386409 ... -0.82711113 -0.87989986\n",
            "   -0.84322508]\n",
            "  [-0.91172889 -0.01295495 -0.87441747 ... -1.08076067 -1.16272543\n",
            "   -0.99008345]\n",
            "  [-1.00537809  0.06925729 -0.93396585 ... -1.23463972 -1.3201589\n",
            "   -1.04760979]\n",
            "  ...\n",
            "  [-1.05805683 -0.31554334 -0.92963508 ... -1.15770873 -1.20178347\n",
            "   -1.06486896]\n",
            "  [-1.05024335 -0.14623875 -0.9597456  ... -1.23094786 -1.28007815\n",
            "   -1.11444289]\n",
            "  [-0.86162568  0.6313809  -0.79817965 ... -0.91096899 -0.95061798\n",
            "   -0.9141417 ]]\n",
            "\n",
            " [[-0.91172889 -0.01295495 -0.87441747 ... -1.08076067 -1.16272543\n",
            "   -0.99008345]\n",
            "  [-1.00537809  0.06925729 -0.93396585 ... -1.23463972 -1.3201589\n",
            "   -1.04760979]\n",
            "  [-1.15795837 -0.11477343 -0.96723275 ... -1.31061817 -1.38785608\n",
            "   -1.08143178]\n",
            "  ...\n",
            "  [-1.05024335 -0.14623875 -0.9597456  ... -1.23094786 -1.28007815\n",
            "   -1.11444289]\n",
            "  [-0.86162568  0.6313809  -0.79817965 ... -0.91096899 -0.95061798\n",
            "   -0.9141417 ]\n",
            "  [-0.57421315 -0.93972896 -0.46903885 ... -0.42332945 -0.46789177\n",
            "   -0.55669139]]]\n",
            "$$$$$$$$$$$$$$$$$$\n",
            "[0.01658115 0.01644887 0.01392534 0.01422053 0.01229865 0.00972776\n",
            " 0.00867076 0.00892153 0.01207872 0.01647356 0.01615604 0.01500122\n",
            " 0.0167847  0.02261649 0.02360776 0.02452643 0.02698428 0.03263853\n",
            " 0.02838046 0.0310246  0.0321993  0.02819379 0.02367704 0.02396434\n",
            " 0.018583   0.02006291 0.01950072 0.02265231 0.02314761 0.01812537\n",
            " 0.00956141 0.01002206 0.00695038 0.00540218 0.00649334 0.00518429\n",
            " 0.00660587 0.00821767 0.00931347 0.01582522 0.01621642 0.01604295\n",
            " 0.01925161 0.02107853 0.00849757 0.0070789  0.01565774 0.01916478\n",
            " 0.01401718 0.01344408 0.01034613 0.00969791 0.01075147 0.01443171\n",
            " 0.01375368 0.01641316 0.01690522 0.01363059 0.01239572 0.02820727\n",
            " 0.02706274 0.03128517 0.03061225 0.02674777 0.0226456  0.01510742\n",
            " 0.01384968 0.01167405 0.01101683 0.00934521 0.0092174  0.00894502\n",
            " 0.00960887 0.00546016 0.00565788 0.01206904 0.01564281 0.01575449\n",
            " 0.01574223 0.01591303 0.01185865 0.00558475 0.00573126 0.00536756\n",
            " 0.00604959 0.00303584 0.00305214 0.0104105  0.01003649 0.01094347\n",
            " 0.01082301 0.01409711 0.01320463 0.02046955 0.01959908 0.02038922\n",
            " 0.02992722 0.03242985 0.02525232 0.03088863 0.03048972 0.01356763\n",
            " 0.02177392 0.02274166 0.0239988  0.02498421 0.02297674 0.01852934\n",
            " 0.01526768 0.01803843 0.01777994 0.02168908 0.05283721 0.06135608\n",
            " 0.05740498 0.06124139 0.06127047 0.04188313 0.0349393  0.02497693\n",
            " 0.0242276  0.03591097 0.02793336 0.02784666 0.02193783 0.0194116\n",
            " 0.00432954 0.00404744 0.01198148 0.01195197 0.01093781 0.0106387\n",
            " 0.00853092 0.01595972 0.01561462 0.01549642 0.01519679 0.01633771\n",
            " 0.00644136 0.00870514 0.01349936 0.01984896 0.01847835 0.02126085\n",
            " 0.0218874  0.0230764  0.01840597 0.01858194 0.0166817  0.0220642\n",
            " 0.02173743 0.02940537 0.03066572 0.03305737 0.03401424 0.0246027\n",
            " 0.02354677 0.01871444 0.01790165 0.02144812 0.02031551 0.02137692\n",
            " 0.02111941 0.02296861 0.01525515 0.01669552 0.01628707 0.0131568\n",
            " 0.01382618 0.01368438 0.01115956 0.01118074 0.01091927 0.00487038\n",
            " 0.00532377 0.00470857 0.00471091 0.01142992 0.01144337 0.01413047\n",
            " 0.01600479 0.01969938 0.01666903 0.01707246 0.01630034 0.0152526\n",
            " 0.02144472 0.02751147 0.02673544 0.0278577  0.02815695 0.0207339\n",
            " 0.01227964 0.02133929 0.01665654 0.01826685 0.01816911 0.01820562\n",
            " 0.00960425 0.00909611 0.00899242 0.01187913 0.01523953 0.01519298\n",
            " 0.0192084  0.01891998 0.010463   0.0105996  0.01360099 0.01103831\n",
            " 0.01236519 0.0108059  0.00890935 0.00803958 0.00808686 0.01050686\n",
            " 0.01009772 0.01024592 0.00896467 0.00973217 0.00502041 0.0060571\n",
            " 0.00651612 0.00624908 0.00700831 0.00652003 0.00618053 0.00629767\n",
            " 0.0083634  0.00900904 0.01003294 0.00901974 0.01220903 0.01217357\n",
            " 0.01332609 0.01169683 0.00924914 0.00932588 0.00987151 0.00909439\n",
            " 0.0093536  0.00975013 0.00798102 0.00828214 0.01189389 0.01147718\n",
            " 0.01142665 0.01668842 0.01694362 0.01458934 0.01472795 0.01524071\n",
            " 0.0162221  0.01822313 0.01773328 0.01651045 0.01680327 0.01148143\n",
            " 0.01312327 0.02060673 0.01746681 0.02015685 0.02127158 0.02917684\n",
            " 0.02133082 0.01629192 0.01676039 0.01650755 0.01064498 0.00890362\n",
            " 0.01211514 0.01062052 0.01637348 0.01600519 0.0167101  0.01397077\n",
            " 0.01393007 0.00737196 0.00799769 0.00707274 0.01133755 0.01126958\n",
            " 0.01417131 0.01357984 0.01090321 0.00968406 0.00991858 0.00507851\n",
            " 0.00587077 0.00470996 0.00608701 0.00637849 0.00841441 0.00921439\n",
            " 0.04682072 0.05338705 0.05321183 0.05143143 0.0534651  0.02158339\n",
            " 0.01744301 0.01068289 0.01057116 0.02073705 0.03045701 0.0253212\n",
            " 0.02406746 0.02221231 0.04645246 0.03958041 0.03960738 0.0390337\n",
            " 0.03185376 0.0068513  0.00507705 0.00972455 0.0102742  0.01250509\n",
            " 0.014914   0.03425918 0.03915376 0.03923513 0.03919975 0.0368963\n",
            " 0.02558971 0.02179359 0.02575863 0.03723891 0.03654392 0.03655854\n",
            " 0.02400689 0.02433664 0.01385381 0.01370793 0.01260864 0.01605885\n",
            " 0.01619339 0.01260894 0.01450524 0.01329494 0.01464124 0.01314022\n",
            " 0.01550848 0.01557534 0.03577498 0.04334804 0.04073104 0.0421828\n",
            " 0.03761028 0.03263566 0.01289557 0.01278992 0.01308288 0.00987416\n",
            " 0.00612695 0.01090542 0.01173132 0.0115287  0.01029979 0.01001886\n",
            " 0.01013492 0.01382568 0.01411854 0.02056842 0.02080767 0.01992447\n",
            " 0.01551982 0.01647635 0.01202702 0.0127616  0.0130478  0.01482056\n",
            " 0.01848161 0.01846184 0.01841059 0.01835362 0.01787742 0.00949392\n",
            " 0.00766571 0.00463801 0.00555199 0.00419528 0.00380534 0.00671555\n",
            " 0.00563002 0.00567708 0.00885541 0.00907483 0.00935302 0.00888578\n",
            " 0.01207091 0.01193044 0.01503192 0.01340349 0.01304874 0.01282505\n",
            " 0.01196085 0.00809172 0.01185992 0.01132837 0.00636772 0.0063649\n",
            " 0.00456988 0.00392083 0.00751442 0.00741226 0.00645107 0.00488504\n",
            " 0.00592462 0.00429945 0.00455984 0.0059104  0.00599059 0.0079265\n",
            " 0.01087642 0.01741999 0.01860908 0.01932189 0.02311398 0.02168874]\n",
            "Transformer DB features\n",
            "8\n",
            "14/14 [==============================] - 1s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-07c24de7141f>:17: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  ResultsCollection=ResultsCollection.append(IterResults, ignore_index=True)\n",
            "\r  1%|          | 4/744 [00:55<2:51:45, 13.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results\n",
            "{'Date_Forecast': datetime.date(2020, 1, 7), 'Forecast_T_ANN_ARCH': 0.021076763, 'Forecast_GARCH': 0.049495004277374355, 'Forecast_GJR_GARCH': 0.06445888110530744, 'Forecast_TARCH': 0.04996493726185646, 'Forecast_EGARCH': 0.05089914026099043, 'Forecast_AVGARCH': 0.047359273644691925, 'Forecast_FIGARCH': 0.05514271560602326, 'ReturnForecast': 0.005843971997304465, 'TrueSD': 0.010898563232370328, 'VaR_T_ANN_ARCH': 0.06737465027588814, 'VaR_GARCH': 0.06949235877626479, 'VaR_GJR_GARCH': 0.07899229893538583, 'VaR_TARCH': 0.06951979595331535, 'VaR_EGARCH': 0.07048547439928632, 'VaR_AVGARCH': 0.06804093562267038, 'VaR_FIGARCH': 0.07466567758457944}\n",
            "             Price    Open    High     Low\n",
            "Date                                      \n",
            "2018-04-03  538.16  526.90  541.85  523.26\n",
            "2018-04-04  522.86  542.00  544.56  520.28\n",
            "2018-04-05  544.38  533.30  550.00  531.50\n",
            "2018-04-06  548.42  546.33  551.39  541.50\n",
            "2018-04-09  556.13  548.80  557.90  545.46\n",
            "...            ...     ...     ...     ...\n",
            "2020-01-07  909.57  912.50  926.50  906.50\n",
            "2020-01-08  914.55  897.10  916.68  896.16\n",
            "2020-01-09  939.52  949.99  949.99  920.90\n",
            "2020-01-10  937.23  937.51  943.49  933.83\n",
            "2020-01-13  945.52  939.98  946.80  936.50\n",
            "\n",
            "[439 rows x 4 columns]\n",
            "////\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld\n",
            "Date                                                         \n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047\n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348\n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111\n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372\n",
            "2018-04-17      0.007381  0.016372  0.010582         0.012969\n",
            "...                  ...       ...       ...              ...\n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864\n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587\n",
            "2020-01-03     -0.016943  0.007927  0.023114         0.013461\n",
            "2020-01-06     -0.032980  0.010876  0.021689        -0.016943\n",
            "2020-01-07      0.005844  0.017420  0.010899        -0.032980\n",
            "\n",
            "[429 rows x 4 columns]\n",
            "GARCH\n",
            "Date\n",
            "2018-04-11    1.615307\n",
            "2018-04-12    1.508782\n",
            "2018-04-13    1.435491\n",
            "2018-04-16    1.694587\n",
            "2018-04-17    1.654971\n",
            "                ...   \n",
            "2020-01-01    1.352717\n",
            "2020-01-02    1.334974\n",
            "2020-01-03    1.429731\n",
            "2020-01-06    1.628126\n",
            "2020-01-07    2.217622\n",
            "Name: cond_vol, Length: 429, dtype: float64\n",
            "---------\n",
            "GJR GARCH\n",
            "Date\n",
            "2018-04-11    1.605663\n",
            "2018-04-12    1.491983\n",
            "2018-04-13    1.409462\n",
            "2018-04-16    1.801634\n",
            "2018-04-17    1.684357\n",
            "                ...   \n",
            "2020-01-01    1.288483\n",
            "2020-01-02    1.271863\n",
            "2020-01-03    1.312820\n",
            "2020-01-06    1.657336\n",
            "2020-01-07    2.506794\n",
            "Name: cond_vol, Length: 429, dtype: float64\n",
            "---------\n",
            "T_ANN_ARCH_FIT Data_AR\n",
            "            DailyReturns        SD    TrueSD  DailyReturnsOld  CV_GARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-11      0.001348  0.029296  0.012233        -0.027047  0.016153   \n",
            "2018-04-12      0.000111  0.024242  0.013067         0.001348  0.015088   \n",
            "2018-04-13     -0.019372  0.015647  0.013197         0.000111  0.014355   \n",
            "2018-04-16      0.012969  0.016668  0.012913        -0.019372  0.016946   \n",
            "2018-04-17      0.007381  0.016372  0.010582         0.012969  0.016550   \n",
            "...                  ...       ...       ...              ...       ...   \n",
            "2020-01-01     -0.001587  0.005910  0.018609        -0.004864  0.013527   \n",
            "2020-01-02      0.013461  0.005991  0.019322        -0.001587  0.013350   \n",
            "2020-01-03     -0.016943  0.007927  0.023114         0.013461  0.014297   \n",
            "2020-01-06     -0.032980  0.010876  0.021689        -0.016943  0.016281   \n",
            "2020-01-07      0.005844  0.017420  0.010899        -0.032980  0.022176   \n",
            "\n",
            "            CV_GJR_GARCH  CV_TARCH  CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                                                   \n",
            "2018-04-11      0.016057  0.012455   0.016095    0.013245    0.017777  \n",
            "2018-04-12      0.014920  0.011783   0.014228    0.012166    0.015738  \n",
            "2018-04-13      0.014095  0.011410   0.013098    0.011661    0.014708  \n",
            "2018-04-16      0.018016  0.015526   0.016711    0.015341    0.017931  \n",
            "2018-04-17      0.016844  0.014816   0.016943    0.016036    0.016607  \n",
            "...                  ...       ...        ...         ...         ...  \n",
            "2020-01-01      0.012885  0.012145   0.012658    0.012934    0.012796  \n",
            "2020-01-02      0.012719  0.012096   0.012269    0.012555    0.012466  \n",
            "2020-01-03      0.013128  0.011994   0.013980    0.014171    0.013792  \n",
            "2020-01-06      0.016573  0.015458   0.016650    0.016610    0.016230  \n",
            "2020-01-07      0.025068  0.021973   0.022471    0.021653    0.023440  \n",
            "\n",
            "[429 rows x 10 columns]\n",
            "==================\n",
            "XDATA_AR\n",
            "                  SD  DailyReturnsOld  CV_GARCH  CV_GJR_GARCH  CV_TARCH  \\\n",
            "Date                                                                      \n",
            "2018-04-11  0.029296        -0.027047  0.016153      0.016057  0.012455   \n",
            "2018-04-12  0.024242         0.001348  0.015088      0.014920  0.011783   \n",
            "2018-04-13  0.015647         0.000111  0.014355      0.014095  0.011410   \n",
            "2018-04-16  0.016668        -0.019372  0.016946      0.018016  0.015526   \n",
            "2018-04-17  0.016372         0.012969  0.016550      0.016844  0.014816   \n",
            "...              ...              ...       ...           ...       ...   \n",
            "2020-01-01  0.005910        -0.004864  0.013527      0.012885  0.012145   \n",
            "2020-01-02  0.005991        -0.001587  0.013350      0.012719  0.012096   \n",
            "2020-01-03  0.007927         0.013461  0.014297      0.013128  0.011994   \n",
            "2020-01-06  0.010876        -0.016943  0.016281      0.016573  0.015458   \n",
            "2020-01-07  0.017420        -0.032980  0.022176      0.025068  0.021973   \n",
            "\n",
            "            CV_EGARCH  CV_AVGARCH  CV_FIGARCH  \n",
            "Date                                           \n",
            "2018-04-11   0.016095    0.013245    0.017777  \n",
            "2018-04-12   0.014228    0.012166    0.015738  \n",
            "2018-04-13   0.013098    0.011661    0.014708  \n",
            "2018-04-16   0.016711    0.015341    0.017931  \n",
            "2018-04-17   0.016943    0.016036    0.016607  \n",
            "...               ...         ...         ...  \n",
            "2020-01-01   0.012658    0.012934    0.012796  \n",
            "2020-01-02   0.012269    0.012555    0.012466  \n",
            "2020-01-03   0.013980    0.014171    0.013792  \n",
            "2020-01-06   0.016650    0.016610    0.016230  \n",
            "2020-01-07   0.022471    0.021653    0.023440  \n",
            "\n",
            "[429 rows x 8 columns]\n",
            "YDATA_AR\n",
            "Date\n",
            "2018-04-11    0.012233\n",
            "2018-04-12    0.013067\n",
            "2018-04-13    0.013197\n",
            "2018-04-16    0.012913\n",
            "2018-04-17    0.010582\n",
            "                ...   \n",
            "2020-01-01    0.018609\n",
            "2020-01-02    0.019322\n",
            "2020-01-03    0.023114\n",
            "2020-01-06    0.021689\n",
            "2020-01-07    0.010899\n",
            "Name: TrueSD, Length: 429, dtype: float64\n",
            "Transformer DB features\n",
            "8\n",
            "For loop transformer db\n",
            "%%%%%%%%%%%%%%%%%%%\n",
            "[[[ 1.2232512  -1.45162959 -0.50025734 ... -0.54149352 -1.14020069\n",
            "   -0.33483833]\n",
            "  [ 0.73041153  0.0110526  -0.67565538 ... -0.88091011 -1.35128835\n",
            "   -0.63156367]\n",
            "  [-0.10766367 -0.05267012 -0.79633169 ... -1.08626762 -1.45010825\n",
            "   -0.78132124]\n",
            "  ...\n",
            "  [-0.346631    0.06996662 -0.73000272 ... -0.80485893 -0.92386054\n",
            "   -0.84616533]\n",
            "  [-0.37428992 -1.01320449 -0.36858294 ... -0.29086388 -0.39238744\n",
            "   -0.39527897]\n",
            "  [-0.60158852  0.01660639 -0.58195479 ... -0.6998783  -0.82253175\n",
            "   -0.74025427]]\n",
            "\n",
            " [[ 0.73041153  0.0110526  -0.67565538 ... -0.88091011 -1.35128835\n",
            "   -0.63156367]\n",
            "  [-0.10766367 -0.05267012 -0.79633169 ... -1.08626762 -1.45010825\n",
            "   -0.78132124]\n",
            "  [-0.00809789 -1.0562642  -0.36971936 ... -0.42956415 -0.72989947\n",
            "   -0.31246133]\n",
            "  ...\n",
            "  [-0.37428992 -1.01320449 -0.36858294 ... -0.29086388 -0.39238744\n",
            "   -0.39527897]\n",
            "  [-0.60158852  0.01660639 -0.58195479 ... -0.6998783  -0.82253175\n",
            "   -0.74025427]\n",
            "  [-0.0354852   1.22547474 -0.1336521  ... -0.05912166 -0.17458283\n",
            "   -0.16752934]]\n",
            "\n",
            " [[-0.10766367 -0.05267012 -0.79633169 ... -1.08626762 -1.45010825\n",
            "   -0.78132124]\n",
            "  [-0.00809789 -1.0562642  -0.36971936 ... -0.42956415 -0.72989947\n",
            "   -0.31246133]\n",
            "  [-0.03703341  0.60967012 -0.43494891 ... -0.38753773 -0.59392057\n",
            "   -0.50512311]\n",
            "  ...\n",
            "  [-0.60158852  0.01660639 -0.58195479 ... -0.6998783  -0.82253175\n",
            "   -0.74025427]\n",
            "  [-0.0354852   1.22547474 -0.1336521  ... -0.05912166 -0.17458283\n",
            "   -0.16752934]\n",
            "  [-0.132426    0.00517751 -0.41223406 ... -0.53341732 -0.66516812\n",
            "   -0.60129254]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.90070334 -0.56594447 -0.7864139  ... -0.8315508  -0.87798667\n",
            "   -0.84053193]\n",
            "  [-0.91066497 -0.0072782  -0.8749897  ... -1.08038617 -1.15179922\n",
            "   -0.98312274]\n",
            "  [-1.00439099  0.07467829 -0.93425809 ... -1.23670131 -1.31278554\n",
            "   -1.04032066]\n",
            "  ...\n",
            "  [-1.05711294 -0.30892529 -0.93262305 ... -1.16614828 -1.20106062\n",
            "   -1.05942366]\n",
            "  [-1.04929304 -0.14014738 -0.96183795 ... -1.23694514 -1.27522795\n",
            "   -1.10755514]\n",
            "  [-0.86052068  0.63505322 -0.80581608 ... -0.9259833  -0.95881273\n",
            "   -0.91454961]]\n",
            "\n",
            " [[-0.91066497 -0.0072782  -0.8749897  ... -1.08038617 -1.15179922\n",
            "   -0.98312274]\n",
            "  [-1.00439099  0.07467829 -0.93425809 ... -1.23670131 -1.31278554\n",
            "   -1.04032066]\n",
            "  [-1.15709641 -0.10877994 -0.96753778 ... -1.31207164 -1.37876912\n",
            "   -1.07439357]\n",
            "  ...\n",
            "  [-1.04929304 -0.14014738 -0.96183795 ... -1.23694514 -1.27522795\n",
            "   -1.10755514]\n",
            "  [-0.86052068  0.63505322 -0.80581608 ... -0.9259833  -0.95881273\n",
            "   -0.91454961]\n",
            "  [-0.57287242 -0.93116917 -0.47914954 ... -0.44068884 -0.48162724\n",
            "   -0.55993662]]\n",
            "\n",
            " [[-1.00439099  0.07467829 -0.93425809 ... -1.23670131 -1.31278554\n",
            "   -1.04032066]\n",
            "  [-1.15709641 -0.10877994 -0.96753778 ... -1.31207164 -1.37876912\n",
            "   -1.07439357]\n",
            "  [-1.05572582  0.24664335 -0.97151351 ... -1.28715504 -1.33761447\n",
            "   -1.0805876 ]\n",
            "  ...\n",
            "  [-0.86052068  0.63505322 -0.80581608 ... -0.9259833  -0.95881273\n",
            "   -0.91454961]\n",
            "  [-0.57287242 -0.93116917 -0.47914954 ... -0.44068884 -0.48162724\n",
            "   -0.55993662]\n",
            "  [ 0.06519622 -1.7572563   0.49148069 ...  0.61718199  0.50538409\n",
            "    0.48891898]]]\n",
            "$$$$$$$$$$$$$$$$$$\n",
            "[0.01644887 0.01392534 0.01422053 0.01229865 0.00972776 0.00867076\n",
            " 0.00892153 0.01207872 0.01647356 0.01615604 0.01500122 0.0167847\n",
            " 0.02261649 0.02360776 0.02452643 0.02698428 0.03263853 0.02838046\n",
            " 0.0310246  0.0321993  0.02819379 0.02367704 0.02396434 0.018583\n",
            " 0.02006291 0.01950072 0.02265231 0.02314761 0.01812537 0.00956141\n",
            " 0.01002206 0.00695038 0.00540218 0.00649334 0.00518429 0.00660587\n",
            " 0.00821767 0.00931347 0.01582522 0.01621642 0.01604295 0.01925161\n",
            " 0.02107853 0.00849757 0.0070789  0.01565774 0.01916478 0.01401718\n",
            " 0.01344408 0.01034613 0.00969791 0.01075147 0.01443171 0.01375368\n",
            " 0.01641316 0.01690522 0.01363059 0.01239572 0.02820727 0.02706274\n",
            " 0.03128517 0.03061225 0.02674777 0.0226456  0.01510742 0.01384968\n",
            " 0.01167405 0.01101683 0.00934521 0.0092174  0.00894502 0.00960887\n",
            " 0.00546016 0.00565788 0.01206904 0.01564281 0.01575449 0.01574223\n",
            " 0.01591303 0.01185865 0.00558475 0.00573126 0.00536756 0.00604959\n",
            " 0.00303584 0.00305214 0.0104105  0.01003649 0.01094347 0.01082301\n",
            " 0.01409711 0.01320463 0.02046955 0.01959908 0.02038922 0.02992722\n",
            " 0.03242985 0.02525232 0.03088863 0.03048972 0.01356763 0.02177392\n",
            " 0.02274166 0.0239988  0.02498421 0.02297674 0.01852934 0.01526768\n",
            " 0.01803843 0.01777994 0.02168908 0.05283721 0.06135608 0.05740498\n",
            " 0.06124139 0.06127047 0.04188313 0.0349393  0.02497693 0.0242276\n",
            " 0.03591097 0.02793336 0.02784666 0.02193783 0.0194116  0.00432954\n",
            " 0.00404744 0.01198148 0.01195197 0.01093781 0.0106387  0.00853092\n",
            " 0.01595972 0.01561462 0.01549642 0.01519679 0.01633771 0.00644136\n",
            " 0.00870514 0.01349936 0.01984896 0.01847835 0.02126085 0.0218874\n",
            " 0.0230764  0.01840597 0.01858194 0.0166817  0.0220642  0.02173743\n",
            " 0.02940537 0.03066572 0.03305737 0.03401424 0.0246027  0.02354677\n",
            " 0.01871444 0.01790165 0.02144812 0.02031551 0.02137692 0.02111941\n",
            " 0.02296861 0.01525515 0.01669552 0.01628707 0.0131568  0.01382618\n",
            " 0.01368438 0.01115956 0.01118074 0.01091927 0.00487038 0.00532377\n",
            " 0.00470857 0.00471091 0.01142992 0.01144337 0.01413047 0.01600479\n",
            " 0.01969938 0.01666903 0.01707246 0.01630034 0.0152526  0.02144472\n",
            " 0.02751147 0.02673544 0.0278577  0.02815695 0.0207339  0.01227964\n",
            " 0.02133929 0.01665654 0.01826685 0.01816911 0.01820562 0.00960425\n",
            " 0.00909611 0.00899242 0.01187913 0.01523953 0.01519298 0.0192084\n",
            " 0.01891998 0.010463   0.0105996  0.01360099 0.01103831 0.01236519\n",
            " 0.0108059  0.00890935 0.00803958 0.00808686 0.01050686 0.01009772\n",
            " 0.01024592 0.00896467 0.00973217 0.00502041 0.0060571  0.00651612\n",
            " 0.00624908 0.00700831 0.00652003 0.00618053 0.00629767 0.0083634\n",
            " 0.00900904 0.01003294 0.00901974 0.01220903 0.01217357 0.01332609\n",
            " 0.01169683 0.00924914 0.00932588 0.00987151 0.00909439 0.0093536\n",
            " 0.00975013 0.00798102 0.00828214 0.01189389 0.01147718 0.01142665\n",
            " 0.01668842 0.01694362 0.01458934 0.01472795 0.01524071 0.0162221\n",
            " 0.01822313 0.01773328 0.01651045 0.01680327 0.01148143 0.01312327\n",
            " 0.02060673 0.01746681 0.02015685 0.02127158 0.02917684 0.02133082\n",
            " 0.01629192 0.01676039 0.01650755 0.01064498 0.00890362 0.01211514\n",
            " 0.01062052 0.01637348 0.01600519 0.0167101  0.01397077 0.01393007\n",
            " 0.00737196 0.00799769 0.00707274 0.01133755 0.01126958 0.01417131\n",
            " 0.01357984 0.01090321 0.00968406 0.00991858 0.00507851 0.00587077\n",
            " 0.00470996 0.00608701 0.00637849 0.00841441 0.00921439 0.04682072\n",
            " 0.05338705 0.05321183 0.05143143 0.0534651  0.02158339 0.01744301\n",
            " 0.01068289 0.01057116 0.02073705 0.03045701 0.0253212  0.02406746\n",
            " 0.02221231 0.04645246 0.03958041 0.03960738 0.0390337  0.03185376\n",
            " 0.0068513  0.00507705 0.00972455 0.0102742  0.01250509 0.014914\n",
            " 0.03425918 0.03915376 0.03923513 0.03919975 0.0368963  0.02558971\n",
            " 0.02179359 0.02575863 0.03723891 0.03654392 0.03655854 0.02400689\n",
            " 0.02433664 0.01385381 0.01370793 0.01260864 0.01605885 0.01619339\n",
            " 0.01260894 0.01450524 0.01329494 0.01464124 0.01314022 0.01550848\n",
            " 0.01557534 0.03577498 0.04334804 0.04073104 0.0421828  0.03761028\n",
            " 0.03263566 0.01289557 0.01278992 0.01308288 0.00987416 0.00612695\n",
            " 0.01090542 0.01173132 0.0115287  0.01029979 0.01001886 0.01013492\n",
            " 0.01382568 0.01411854 0.02056842 0.02080767 0.01992447 0.01551982\n",
            " 0.01647635 0.01202702 0.0127616  0.0130478  0.01482056 0.01848161\n",
            " 0.01846184 0.01841059 0.01835362 0.01787742 0.00949392 0.00766571\n",
            " 0.00463801 0.00555199 0.00419528 0.00380534 0.00671555 0.00563002\n",
            " 0.00567708 0.00885541 0.00907483 0.00935302 0.00888578 0.01207091\n",
            " 0.01193044 0.01503192 0.01340349 0.01304874 0.01282505 0.01196085\n",
            " 0.00809172 0.01185992 0.01132837 0.00636772 0.0063649  0.00456988\n",
            " 0.00392083 0.00751442 0.00741226 0.00645107 0.00488504 0.00592462\n",
            " 0.00429945 0.00455984 0.0059104  0.00599059 0.0079265  0.01087642\n",
            " 0.01741999 0.01860908 0.01932189 0.02311398 0.02168874 0.01089856]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  1%|          | 4/744 [01:04<3:17:51, 16.04s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-07c24de7141f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#Fitting of Transformed ANN-ARCH model, ARCH models and forecasting of the next volatility value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mT_ANN_ARCH_Model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_ANN_ARCH_Fit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLagSD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTimestep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLearningRate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEpochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;31m#VaR of ARCH models is computed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mVaR_ARCH_Models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVaR_AR_Total\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GARCH_fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GJR_GARCH_fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARCH_fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EGARCH_fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AVGARCH_fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FIGARCH_fit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GARCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'GJR_GARCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TARCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EGARCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'AVGARCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT_ANN_ARCH_Model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'FIGARCH'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-75f7a985cef9>\u001b[0m in \u001b[0;36mT_ANN_ARCH_Fit\u001b[0;34m(Data, Lag, LagSD, Timestep, Dropout, LearningRate, Epochs, Alpha, DF, BatchSize)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;31m#Model with transformer layer is defined\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformer_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXData_AR_Norm_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXData_AR_Norm_T\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHeadsAttention\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLearningRate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLearningRate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXData_AR_Norm_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYData_AR_Norm_T\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEpochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m     \u001b[0mForecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDate_Forecast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainPrediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReturnForecast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_ANN_ARCH_Forecast\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mDatabase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLagSD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFor_CV_GARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFor_CV_GJR_GARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFor_CV_TARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFor_CV_EGARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFor_CV_AVGARCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFor_CV_FIGARCH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mScaled_Norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXData_AR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0mVaR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT_ANN_ARCH_VaR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DailyReturnsOld'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mForecast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8T5rqkgF_GBE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}